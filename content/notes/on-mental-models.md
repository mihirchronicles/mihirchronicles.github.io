---
title: "On Mental Models"
tags: ["general"]
date: "2021-09-03"
draft: false
path: "/notes/on-mental-models"
---

Before you proceed, ask yourself, what is the purpose of wisdom?

For me, it is clear, I am in the business of making right decisions and therefore acquiring wisdom is purposeful. For many, this is true as well. I also operate with the mindset of not understanding the world and will most likely won't ever. But if I make 6 out of 10 right decisions, then exercising to acquire wisdom is a worthwhile exercise. Note, it is not to make myself look or sound smart. It is simply to make more right decisions than wrong.

Given the nature of the world and it being so dynamic, it would be foolish to spend time alone in one field. Therefore, mental models can be useful.

We all think of Charlie Munger when we talk about *latticework of mental models*. He is one of the greatest thinkers of our generation, a living legend and a business partner of a famous investor Warren Buffett. Charlie Munger has lived (and still is) an intellectually stimulating life which he credits to mental models. He has spent more time thinking about making right decisions than anyone else I know. It was natural for me to follow his route and conduct a deeper understanding of mental models.

> I think it is undeniably true that the human brain must work in models. The trick is to have your brain work better than the other person’s brain because it understands the most fundamental models–ones that will do most work per unit. – Charlie Munger

> One of the advantages of a fellow like Buffett, whom I've worked with all these years, is that he automatically thinks in terms of decision trees and the elementary math of permutations and combinations. – Charlie Munger

**Galileo vs Aristotelian**: The history of science and knowledge is full of discoveries based on exploiting the power of mental models. Often these models are taught to students in business, design and engineering schools.

Consider the example of a heavy stone swinging back and forth on a string. Before Galileo, an Aristotelian looking at the swinging stone thought that a heavy object moved naturally from a higher position to a state of rest at a lower one. The Aristotelian would think that what the stone was really doing was falling with difficulty. When Galileo saw the swinging stone though, he saw a pendulum. He thought that what the stone was really doing was repeating the same motion again and again, almost perfectly.

The suggestive powers of the two models are quite different. The Aristotelian who saw the swinging stone as an object falling would observe the stone’s weight, the height to which it had been raised, and the time it took to come to rest. For Galileo’s pendulum model the prominent factors were different. Galileo observed the stone’s weight, the radius of the pendulum’s swing, the angular displacement, and the time per swing. Galileo discovered laws the Aristotelians couldn’t because their model led them to look at different phenomena and ask different questions.

**Latticework of mental models**: Mental models are big ideas from big disciplines, like business, psychology, science, engineering, and more. An understanding of the key concepts from different disciplines will help you ask the right questions to help make wise decisions. The task of decision-making is quite challenging in a complex and interconnected world. To be a world-class thinker and a better leader, you must develop a mind that can jump boundaries from one discipline to another.

As the Japanese proverb goes, “The frog in the well knows nothing of the mighty ocean.” You ought to jump the boundaries of your specialized field to overcome complex and dynamic systems of life. Being in one well will cloud your thought process preventing you to understand life beyond the well. To clear up your blind spots, learn to explore wells, ponds, rivers, lagoons, canals and oceans. Combining models from various disciplines produces a cohesive understanding. 

So, how do you achieve worldly wisdom by jumping boundaries?

1. Acquire fundamental knowledge (big ideas) from big disciplines.
2. Understand common patterns, fallacies and biases of human nature.
3. Question your models and test them against reality.
4. Apply these models and biases rigorously in your decision-making.
5. Not all models are useful so handle them with care.

**Mental models vs algorithms**: A mental model is more like a searchlight than a road map. It doesn’t tell you the answer directly, or where to find the answer, it shows you how to look for it. A mental model is heuristic–it enables you to learn and discover for yourself, it is a far cry from an algorithm's well-defined instructions for carrying out a particular task. Algorithms are predictable, deterministic, and not subject to chance.

A mental model is a technique that helps you look for an answer. Its results are subject to chance because a mental model tells you how to look, not what to find. It doesn’t tell you how to get directly from point A to point B. In effect, a mental model is an algorithm in a clown suit. It’s less predictable, it’s more fun, and it comes without a 30-day, money-back guarantee.

Here is an algorithm for driving to your grandma's house. Take Highway 290 West to Rosemont in Chicago. Take the State Street exit and drive 2.5 miles up the Congress Parkway. Turn right at the light by the gas station, and then take the first left. Turn into the driveway of the large white house on the left, at 111 Windy City.

Here is a mental model for getting to your grandma's house. Find the last letter we mailed you. Drive to the town in the return address. When you get to town, ask someone where our house is. Everyone knows us-someone will be glad to help you. If you can’t find anyone, call us from a public phone, and we’ll give you the instructions directly. A mental model tells you how to discover the instructions for yourself, or at least where to look for help.

**Map is not the territory**: Alfred Korzybski, a famous mathematician in 1931 made a simple observation—*the map is not the territory.* This allows you to assess the usefulness of models. Maps (mental models) are thought of as a representation of reality. They distill complex ideas into simple concepts that can be processed by our brains which enable us for faster decision-making. But maps do not represent reality. A map indeed can be flawed when entering uncharted territories. Ask early European sailors who went on voyages to explore deep seas and new lands.

> (History) offers a ridiculous spectacle of a fragment expounding the whole. — Will Durant

This brings me to the next point. *All models are wrong, but some are useful*. Those words came from a British statistician, George Box. He revealed the fallacy of our desire to organize the world in patterns. We at times confuse models with reality because we prefer simplification. But that is not how reality works. Models never reflect complete truth.

> Remember that all models are wrong; the practical question is how wrong do they have to be to not be useful. — George Box

Some mental models work better than others in some situations and knowing which models to use and when is a key of good judgment. Focusing on timeless models that have been around for a long time and consistently testing them against reality will help you use them right.

> No idea is true just because someone says so. Test ideas by the evidence gained from observation and experiment! If a favorite idea fails a well-designed test, it’s wrong! — Richard Feynman

To overcome the challenge of model thinking, always have bias for action. Keep in mind that when in doubt, it'll be action that produces information. So when map and terrain differ, follow the terrain.

> The world doesn’t have the luxury of waiting for complete answers before it takes action. — Daniel Gilbert

**Mungerism**: Munger gave a famous speech, “*A Lesson on Elementary Wisdom*” in 1995 speech at USC Business School about worldly wisdom and latticework of mental models. Below are some references from his speech.

> What is elementary, worldly wisdom? Well, the first rule is that you can’t really know anything if you just remember isolated facts and try and bang ‘em back. If the facts don’t hang together on a latticework of theory, you don’t have them in a usable form. You’ve got to have models in your head. And you’ve got to array your experience — both vicarious and direct — on this latticework of models. — Charlie Munger

> You may have noticed students who just try to remember and pound back what is remembered. Well, they fail in school and in life. You’ve got to hang experience on a latticework of models in your head. — Charlie Munger

> What are the models? Well, the first rule is that you’ve got to have multiple models — because if you just have one or two that you’re using, the nature of human psychology is such that you’ll torture reality so that it fits your models, or at least you’ll think it does. You become the equivalent of a chiropractor who, of course, is the great boob in medicine. — Charlie Munger

> It’s like the old saying, “To the man with only a hammer, every problem looks like a nail.” And of course, that’s the way the chiropractor goes about practicing medicine. But that’s a perfectly disastrous way to think and a perfectly disastrous way to operate in the world. — Charlie Munger

> So you’ve got to have multiple models. And the models have to come from multiple disciplines—because all the wisdom of the world is not to be found in one little academic department. That’s why poetry professors, by and large, are so unwise in a worldly sense. They don’t have enough models in their heads. — Charlie Munger

> So you’ve got to have models across a fair array of disciplines. — Charlie Munger

> You may say, “My God, this is already getting way too tough.” But, fortunately, it isn’t that tough—because 80 or 90 important models will carry about 90% of the freight in making you a worldly-wise person. And, of those, only a mere handful really carry very heavy freight. — Charlie Munger

> You have to learn all the big ideas in the key disciplines in a way that they’re in a mental latticework in your head and you automatically use them for the rest of your life. If you do that, I solemnly promise you that one day you’ll be walking down the street and you’ll look to your right and left and you’ll think “my heavenly days, I’m now one of the few competent people in my whole age cohort.” If you don’t do it, many of the brightest of you will live in the middle ranks or in the shallows. — Charlie Munger

> I went through life constantly practicing (because if you don’t practice it, you lose it) the multi-disciplinary approach and I can’t tell you what that’s done for me. It’s made life more fun, it’s made me more constructive, its made me more helpful to others, its made me enormously rich. – Charlie Munger

He also gave another famous speech, “*The Psychology of Human Misjudgement*” in 1995 at Harvard Law School about human psychology and biases.

> I was aware that man was a “social animal,” greatly and automatically influenced by behavior he observed in men around him. I also knew that man lived, like barnyard animals and monkeys, in limited size dominance hierarchies, wherein he tended to respect authority and to like and cooperate with his own hierarchy members while displaying considerable distrust and dislike for competing men not in his own hierarchy. — Charlie Munger

Below are the collection of mental models accumulated from his various resources and talks. The checklist is grouped based on their source of discipline. These mental models should equip everyone make better decisions, so they can live a better life.

## Engineering
| Model | Definition | 
| -------------|:-------------:|
| _Feedback loop_ | A feedback loop occurs when the output of a system feeds back into itself as an input, thereby further affecting the output. |
| _Margin of safety_ | Describes the capacity of a system to carry load beyond its actual capability. |

<details>
    <summary><strong>Feedback loop</strong></summary>
    <br>

A feedback loop occurs when the output of a system feeds back into itself as an input, thereby further affecting the output.

Part of a control system in which the outputs are fed back in as inputs. Take the heating in your home—your furnace will push out heat, the thermostat will check the temperature and use this information to turn the furnace on and off. The system is a loop. The concept is also known as homeostasis in biological field. Feedback occurs when outputs of a system are routed back as inputs as of a chain of cause-and-effect that forms a circuit or loop. The system can then be said to feed back into itself. Feedback loops are important if we want to alter a state or fill in a gap in systems. Feedback often refer to as information about the state or a gap but can be useless unless translated into an action. The notion of cause-and-effect has to be handled carefully when applied to feedback systems:

> Simple causal reasoning about a feedback system is difficult because the first system influences the second and second system influences the first, leading to a circular argument. This makes reasoning based upon cause and effect tricky, and it is necessary to analyze the system as a whole. *—  Karl Johan Åström and Richard M.Murray, Feedback Systems: An Introduction for Scientists and Engineers*

The concept first started to appear in Britain but it didn't have a name. One of the first artificial feedback device was a mercury thermostat to regulate temperature of a chicken incubator in 1620 in England. It was built upon a similar device called thermoscope invented by Galileo in 1593. Feedback loops were applied to windmills, steam-engines, electronic amplifiers, circuits and many other well known inventions. [*On Governors*](https://www.maths.ed.ac.uk/~v1ranick/papers/maxwell1.pdf) written by James Clerk Maxwell in 1868 is widely considered a classic in feedback control theory. This was a landmark paper for more theories to evolve in the discipline of mathematics of feedback and control theory.

**Homeostasis**: We might think if the output becomes the input, then the next output should be of higher intensity than the previous one. But that is not the case because there are two types of feedback loops—positive (reinforcing) and negative (balancing or goal-based) feedback loops. The key difference between positive and negative feedback is their response to change. Biological systems operate on a mechanism of inputs and outputs, each caused by and causing a certain event. Feedback loops are important because they allow living organisms to maintain homeostasis. Homeostasis is the mechanism that enables us to keep our internal environment relatively constant—not too hot, or too cold, not too hungry or tired.

**Positive feedback loop**: In *positive feedback loops*, the output gets amplified (either increasing or decreasing intensity). In other words, if the input leads to an increase in output, then the loop will lead to continuously increasing output. If the input decreases the output, then the loop will lead to continuously decreasing output. The curve of positive feedback loop is exponential—either exponential growth, or exponential decline. Positive feedback loops are effective for creating change, but generally result in negative consequences if not moderated by negative feedback loops. Many internet companies are the beneficiaries of positive feedback loops which help create the “network effect.” The more people that use a particular search engine or social network, the more honed the search results become, or the more useful the network becomes to the user. That’s one of the reasons why search networks are a “winner take all,” type of business model. These feedback loops will continue to reinforce themselves until regulators or anti-trust officials take action.

**Negative feedback loop**: In *negative feedback loops* the system stays in equilibrium state whereas an uncontrolled positive feedback loop can cause a system to reach a critical state, a tipping point and then fundamentally change it. Negative feedback loops are also called balancing or goal-seeking loops. In such systems, there is a set limit (or goal), and the aim of the feedback mechanism is to stick to the set limits, thereby maintaining a balance. Negative feedback dampers output, stabilizes the system around an equilibrium point. Consider a thermostat regulating room temperature. This is an example of a negative feedback loop. As the temperature rises, the thermostat turns off the furnace allowing the room to rest at a predetermined temperature. When the temperature falls below that predetermined temperature the furnace reignites to return the room to its equilibrium state. Other examples include body temperature and financial markets.

**Economic cycles**: Usually during a down turn economic cycle (recession) due to negative news, small number of depositors think banks are going broke, so they will run to local branches to withdraw their money. This leads to neighbors and friends flocking to the banks to withdraw more money. This results in bank runs causing ripple effect. A loop that keeps feeding in itself resulting in economic crisis.

**Habit loop**: Feedback loops are important for virtuous cycle of deep and experimental learning. As we learn, try and practice a topic, we can get feedback on our performance (tests). Based on the feedback, we evaluate which methods of learning are most efficient and which aren't. Then we modify our behavior and adjust our learning methods. This loop reinforces our learning, and helps us to improve. As we learn more, we will be able to understand bigger ideas, and this snowballs into a huge intellectual advantage over time. A powerful application of the feedback loop is the [habit loop](https://charlesduhigg.com/how-habits-work/), as popularized by Charles Duhigg. The habit loop explains how we can use feedback (rewards) to reinforce the behavior we want to create within ourselves. A key point to remember is that feedback is most effective when provided immediately and translated into an action otherwise feedback is no good. There are many other known applications of feedback loops on [Wikipedia](https://en.wikipedia.org/wiki/Feedback#Applications).

<br>
</details>
<br>

<details>
    <summary><strong>Margin of safety</strong></summary>
    <br>

Describes the capacity of a system to carry load beyond its actual capability.

Margin of safety originated from engineering but is applicable to any system. Describes the capacity of a system to carry loads beyond its actual capability. When designing such systems, the system should be able to support additional loads which are calculated using detailed analysis. The primary question posed by this concept is how much stronger the system is than it usually needs to be for an intended load. Testing can be impractical when complex systems such as aircraft, buildings or bridges are involved. However, the structure’s ability to carry load must be determined to a reasonable accuracy by conducting a detailed analysis to avoid any unexpected failure. Margin of safety is used widely in many areas of life such as accounting, engineering, investing and time management to name just a few. In its original form, a quantitative “margin of safety” is in fact called a “safety factor.” In structural engineering, the safety factor is calculated as follows:

- Calculated by dividing the load required to cause failure by the maximum load expected to act on a structure.*‍*
- A system with capacity of 6,000 pounds is used to carry no more than 1,000 pounds at a time, then the factor of safety is 6,000 / 1,000 = 6.

The above calculation is generalized to explain the concept. However, between various industries and engineering groups usage is inconsistent and confusing. The concept is heavily used in aerospace and industrial projects but not limited to those industries. Just like Factor of Safety, Margin of Safety is a widely known concept within the business world whether investing in a new project or personal investing. Margin of Safety allows room for an analytical error or bad luck to avoid sizable losses over time. Investing in future is unpredictable and margin of safety allows to protect us from that bad luck. Applying this concept in managing money protects any unexpected downside if the business or stock market were to tumble.

**Factor of safety**: The economics use of steel depends upon quality and its working stress. Structures have two main problems, buckling and bending, and theories in calculating these two properties in steel were established in 1759 and 1826. To arrive at a reasonable working stress, a Factor of Safety against failure was assessed and this was generally taken as a quarter of the average ultimate strength of material. London City Council determined the working stress of steel and introduced a higher Factor of Safety to allow for imperfections in the material. Factor of Safety has evolved and even introduced in other industries mandated by the Federal Airworthiness Regulation.

> Unless otherwise specified, a factor of 1.5 must be applied to the prescribed limit loads which are considered external loads on the structure. This is enforced by civilian and military transport authorities and has the force of law within the United States. — NASA

Margin of safety originated from engineering. Many structural projects within government and private sector apply *Factor of Safety (FoS)* to ensure the structural safety.

> In engineering, a factor of safety (FoS), also known as (and used interchangeably with) safety factor (SF), expresses how much stronger a system is than it needs to be for an intended load. Safety factors are often calculated using detailed analysis because comprehensive testing is impractical on many projects, such as bridges and buildings, but the structure's ability to carry a load must be determined to a reasonable accuracy. Many systems are intentionally built much stronger than needed for normal usage to allow for emergency situations, unexpected loads, misuse, or degradation (reliability). — Wikipedia

**Limitations of margin of safety**: Clearly, the margin of safety model is very powerful, and we’re wise to use it whenever possible to avoid failure. But it has limitations. If time and money are the most important resources, does it make sense to utilize those resources to fail-proof a material to such an extent that any extra unit spent on making it safe does not make it safer? For example, how do you account for weather conditions? Or, how do you account for future government policies when you are investing in a stock market? In both instances, while doing analysis, you have to realize we do not have control over external factors which makes it hard to fail-proof a structure or a system. While also conducting detailed analysis, you have to ensure the biases baked into data or old set of data that is no longer relevant. Judgment is another one. When it comes to things like terrorist attacks, people are not concerned about false alarms. However, using probability of an event can suggest a likelihood of an event such as terroristic attack is very low. The margin-of-safety calculation can be exaggerated without careful judgment.

 <br>
</details>

## Physics
| Model | Definition | 
| -------------|:-------------:|
| _Leverage_ | By using a lever, you can amplify the input force. Think of a see-saw. |
| _Critical mass_ | The amount of reactant necessary for something to happen and to keep happening. |

<details>
    <summary><strong>Leverage</strong></summary>
    <br>

By using a lever, you can amplify the input force. Think of a see-saw.

Mental models are an example of leverage.  They can be leveraged to apply to the complex problems at school or work. By using a lever, you can amplify the input force. Think of a teeter-totter or a see-saw. Push one side down and the other goes up. Make one side short and the other long, and you can lift heavy objects by applying force to the long side. A lever amplifies an input force to provide a greater output force, which is said to provide leverage. The first descriptions of lever are found to be amongst the followers of Aristotle at the Peripatetic school. Egyptians used a lever to build The Great Pyramids.

Archimedes is credited for the principles of leverage. While Archimedes did not invent the lever, he explained the concept of leverage in his literature work, *On the Equilibrium of Planes.* Archimedes designed pulley systems, allowing sailors to use the principle of leverage to lift objects that would otherwise have been too heavy to move.

> Give me a place to stand on, and I will move the Earth. — Archimedes

Leverage refers to the ability to gain an advantage through the use of a tool, and is measured as the ratio of the change in output to the change in input. Focusing on high leverage activities then becomes important. For small amount of additional input, a large increase in output leads to maximizing our scarcest resource which is time. Though leverage is a scientific concept, it has many other applications. In complex systems, leverage plays an important role.

**Complex system**: In complex systems, such as an economy, corporation, living organisms, a city, or an ecosystem, leverage can be earned where a small change in one thing can produce a big change in the entire system. Leverage is clear and specific. For example, how do we solve poverty? A specific and clear leverage can be used such as economic growth. By providing robust jobs, a city can escape poverty.

Whether in system analysis or decision-making, you should always think of applying leverage by working on smaller changes which would output a significant and impactful change.

**Negotiations**: Why do we always pay more for food at the airport, theaters or theme parks? These businesses don't have alternative offerings giving them the ultimate leverage on prices.

> Money is not equal for all people. A strong personal brand adds more lift and leverage. One dollar from me may buy a soda from a car dealership, but one dollar from Justin Bieber may get him a Ferrari. And they'd pay him to drive away. — Jarod Kintz

**Wealth**: Use leverage to build wealth. How can you maximize beyond the hourly input-output? Leverage! If you can only earn with your time on hourly basis, the only way to build wealth is with deep specializations in medicine (doctor), law (lawyer), software (engineering), etc. Using leverage you can go beyond hourly input-output boundaries. When using leverage tools such as money, employees, or products, you can create more value for more people in the same amount of time.

> Humans evolved in societies where there was no leverage. If I was chopping wood or carrying water for you, you knew eight hours put in would be equal to about eight hours of output. Now we’ve invented leverage — through capital, cooperation, technology, productivity, all these means. We live in an age of leverage. As a worker, you want to be as leveraged as possible, so you have a huge impact without as much time or physical effort. — Naval

> A leveraged worker can out-produce a non-leveraged worker by a factor of 1,000 or 10,000. With a leveraged worker, judgment is far more important than how much time they put in or how hard they work. — Naval

 <br>
</details>
<br>

<details>
    <summary><strong>Critical mass</strong></summary>
    <br>

The amount of reactant necessary for something to happen and to keep happening.

A tipping point when the change is slow at first, but then suddenly leads to an explosive change. The concept is critical in understanding the phenomenon of virality. When a nuclear reaction happens, neutrons are released and can cause another reaction. The smallest amount of a material needed to self-sustain a nuclear chain reaction is said to be the critical mass. In social dynamics, critical mass is a sufficient number of adopters of a new idea, technology or innovation in a social system so that the rate of adoption becomes self-sustaining and creates further growth. The point at which critical mass is achieved is sometimes referred to as a threshold within the threshold model of statistical modeling. The notion of a critical mass—that comes out of physics—is a very powerful model.

**Nuclear physics**: Critical mass is defined as the minimum amount of a fissile material required to self-sustaining fission reaction. Critical mass might vary on several factors such as—material, density or its shape. In some nuclear reactions, a reflector made of beryllium is used to speed up the process of reaching critical mass.

**Tipping point**: Both *Critical Mass* and *Tipping Point* have become interchangeable. Mark Granovetter has done research on a model of how fads are created. Consider a hypothetical mob assuming that each person's decision whether to riot or not is dependent on what everyone else is doing. Instigators will begin rioting even if no one else is, while others need to see a critical number of trouble makers before they riot, too. This threshold is assumed to be distributed to some probability distribution. The outcomes may diverge largely although the initial condition of threshold may only differ very slightly. This threshold model of social behavior was proposed previously by Thomas Schelling and later popularized by Malcolm Gladwell's book *The Tipping Point*. Malcolm Gladwell describes tipping point as “the moment of critical mass, the threshold, the boiling point.” He describes ideas, products, messages and behaviors spread just like viruses do.

> Look at the world around you. It may seem like an immovable, implacable place. It is not, with the slightest push in just the right place it can be tipped. — Malcolm Gladwell

**Sociology**: A critical mass can form from a group of people who make a drastic change by altering their behavior, opinions or actions. When enough people follow new ideas, it can become a reality.

**Geology**: A critical mass can occur from tiny natural evolution. Andrew H Knoll, a famous geologist, in his book *A Brief History of Earth* explains that the early Earth was swaddled by a thick atmosphere, but it was air without oxygen. But that changed when Cyanobacteria came along causing the Earth's Greatest Oxygenation Event. Earth's Greatest Oxygenation Event (GOE) was revolutionary, and Cyanobacteria—the only bacteria capable of oxygenic photosynthesis—were the heroes of the revolution. Cyanobacteria gained the upper hand in a world that long favored different photosynthetic microbes. They dominated the planet by producing more oxygen than carbon. Enough Cyanobacteria tipped the oxygen level to sustain a modern life.

**Peter Bevelin on critical mass**: Peter Bevelin is an author of an excellent book *Seeking Wisdom* in which he explains critical mass.

> At a certain scale, a system reaches a critical mass or a limit where the behavior of the system may change dramatically. It may work better, worse, cease to work or change properties. Small interactions over time slowly accumulate into a critical state–where the degree of instability increases. A small event may then trigger a dramatic change like an earthquake.

> A small change may have no effect on a system until a critical threshold is reached. For example, a drug may be ineffective up until a certain threshold and then become effective, or it may become more and more effective, but then become harmful.

> Another example is from chemistry. When a system of chemicals reaches a certain level of interaction, the system undergoes a dramatic change. A small change in a factor may have an unnoticeable effect but a further change may cause a system to reach a critical threshold making the system work better or worse.

> A system may also reach a threshold when its properties suddenly change from one type of order to another. For example, when a ferromagnet is heated to a critical temperature it loses its magnetization. As it is cooled back below that temperature, magnetism returns.

**Munger**: Munger's commentary on critical mass:

> Adding success factors so that a bigger combination drives success, often in non-linear fashion, as one is reminded by the concept of breakpoint and the concept of critical mass in physics. Often results are not linear. You get a little bit more mass, and you get a lollapalooza result. And of course I’ve been searching for lollapalooza results all my life, so I’m very interested in models that explain their occurrence. An extreme of good performance over many factors.

 <br>
</details>

## Mathematics
| Model | Definition | 
| -------------|:-------------:|
| _Power laws_ | Power law is one form of Pareto's principle where the proportion of 80/20 shifts to extreme proportion. |
| _Inversion_ | The thinking in which you want opposite—both forward and backward. |
| _Compound interest_ | Compound interest is the interest you earn on the sum of your initial principal amount and the interest accumulated. |

<details>
    <summary><strong>Power laws</strong></summary>
    <br>

Power law is one form of Pareto's principle where the proportion of 80/20 shifts to extreme proportion.

Power law is a well known concept in seismology, the study of earthquakes. A large scale earthquake releases twice the energy than a small scale earthquake. A large scale earthquake can cause a lot of damage, but they occur rarely. In California, small scale earthquakes are common, but the damage is negligible. However, the impact of one big earthquake can be bigger than the sum of millions of smaller and more common ones. This is one example of power laws. Another example of power law is wealth distribution. Often you hear the top 1% of American household owns 99% of the wealth. The combined wealth of top 1% is orders of magnitude greater than all of 99% combined. This pattern of income distribution can be attributed to the mathematical principle of power law. This is why billionaires are a tiny fraction of our total population. A relationship between two quantities whereby a small change in one, results in a large change in the other. If you double the diameter of a circle, the area would quadruple. Power law is an extension of Pareto's principle which indicates 80% of the outcomes comes from 20% of the action. For example, 80% of the sales come from 20% of the customers; 80% of the world's internet traffic go to 20% of the websites. But a power law skews towards a more extreme proportion. For example, 99% of the traffic goes to 1% of the websites. There is a rich and long history of power law distribution spanning in many fields. Power law distributions have many names, often referred to as long-tail distributions, Pareto distributions, Zipfian distributions, Benford's law, Stefan-Boltzmann law and Steven's power law. The idea of a power law had been suggested by 19th-century researchers, but much of the recent interest in power laws has come recently, specifically from the study of probability distributions.

**Power law equation**: It is primarily in the study of statistical distributions that the name “power law” is used, but mathematically, a power law cannot be a probability distribution, but a distribution that is a power function involving two numbers, the *base* and the *exponent*. In math class, we all once asked, why even care about exponents? You will soon know why! Understanding any complex system such as income inequality or earthquakes require an understanding of power laws. Let's take a look at power laws in mathematical terms to get a better understanding:

***Y=MX^N***

*Y* is a function, *X* is the variable you can change, *N* is the exponent that you can scale and *M* is a constant that does not change. We'll explore two types of relationships— linear and non-linear relationships.

**Linear relationships**: To double a chocolate recipe, you would need twice as much as cocoa. This is simply a linear relationship. Let's assume *M* (constant) is equal to 1 and *N* (exponent) is equal to 2. Ignore *M* here because anything you multiply with 1 will yield the original number. So let's plug some numbers in the equation (*Y= X^N*) and the *Y* will yield the following:

- If X is equal to 1, Y yields to 1
- If X is equal to 2, Y yields to 4
- If X is equal to 3, Y yields to 9

You get the point. A small change in the value of X leads to a proportionally large change in the value of Y. In the above example Y grows linearly. It requires twice the amount to make something twice the big.

**Non-linear relationships**: How about non-linear relationships? It is much different because of complex systems. Let's use the most successful Olympian of all time, Michael Phelps, to understand non-linear relationships. Let's take the same power law equation we explored earlier.

***Y=MX^N***

Michael Phelps has a low and a constant *M* because of some combination of his natural ability to swim and training history. *X,* the base is a number he has a control over, and *N*, the exponent is between 0 and 1. Thus, the relationship between *X* and *Y* becomes less proportional. Let's plug some numbers in now.

- Y yields to 2 when N is 0.5, X is 4 and M is 1
- Y yields to 4 when N is 0.5, X is 16 and M is 1

Let's compare the two scenarios from above and see how it translates into his performance and training. In the first scenario above, Michael Phelps swims 4 extra miles (*X* variable for which he has control over) during his training which leads to an endurance of 2 (*Y*). In the second scenario, he has to swim 4 times more (16 miles) to double his endurance from 2 to 4. As you increase *X*, you are likely to see an exponent of *N* decline. So increasing *X* of 16 to 64 is unlikely to double the endurance again. Eventually, the ratio of swimming extra lanes to an endurance will become nearly infinite. This is called diminishing returns— no matter how much more training time you put in, it will yield to a negligible or less positive result.

What happens when an exponent of *N* is negative? Le't take a scenario where Michael Phelps is injured.

- Y results in 0.5 when X is 4 and N is -(0.5)
- Y results in 0.25 when X is 16 and N is -(0.5).

In the first scenario, swimming 4 extra miles leads to only 0.5 a mile of endurance. In the second scenario that progress shrinks by half again. This wouldn't be smart way to train for Michael Phelps because more training leads to less endurance. This is an inverse relationship between the exponent *X* and *Y*. Power law is complex to understand, but once you understand it becomes easy to see the world as is.

> The greatest shortcoming of the human race is our inability to understand the exponential function. — Albert Allen Bartlett

**Higher order power laws**:

We already know, when *N* is 1, it is called a linear relationship, also called a first-order power law. When *N* is 2, it is called a second-order power law. Commonly found in physics concepts such as kinetic energy. When *N* is 3, it is called a third-order power law. This law is applicable in wind turbines. When N is *4*, it is called a fourth-order power law. This law is applicable in heat radiation.

> We don’t live in a normal world; we live under a power law. — Peter Thiel

**Diminishing returns**: As per everything else, power law should not be a singular lens to see the world. Like everything else, it requires a detailed analysis. As explained earlier, Michael Phelps cannot just rely on putting in more time to get a small percentage of endurance. Power laws have limitations such as law of diminishing return. The exponent starts declining in some applications, no matter how much extra time you put in. There is a perfect example of diminishing return to happiness when you make more money. Most people assume making more money will bring more happiness. But that is not the case. Being able to enjoy basic needs will certainly bring happiness. So, earning from $20k to $60k will bring in joy, but earning from $100k to $115k leads to little change in well-being.

**Applications**: Power law is applicable in many systems, especially complex systems. Below are just to name a few:
- Compounding (Business): Another form of power law is called a compound interest. Small amount of contribution becomes a large amount of money. This is applicable to savings and debt.
- Zip's Law (Language): Another form of power law is called Zip's law which states a small percentage of words make up the majority of usage. The most used word in a language has a higher percent of all words used, while the second is used half as much, and so on. You can use Zip's law to understand several languages by only focusing on the most used words.
- Klieber's Law (Biology): The average lifespan of an animal based on its size can be attributed to power law. The larger the animal, the higher the lifespan, and vice-versa. The relationship between animal's size and its metabolism is identified as Klieber's law which states that an animal’s metabolic rate increases at 3/4ths of the power of the animal’s weight. Larger animals require less energy to burn their food compared to smaller ones which require more energy.

 <br>
</details>
<br>

<details>
    <summary><strong>Inversion</strong></summary>
    <br>

The thinking in which you want opposite—both forward and backward.

Regardless of age, everyone is thinking about success. A common question amongst many—what does *success* mean? But what if we went even one step further about this curiosity? What does *failure* look like? Thinking through inversion broadens your risk analysis in every aspect of life. The thinking in which you want opposite — not only thinking forward but also thinking backward. This trick is a powerful idea because it de-biases us from having blinders. The goal of this exercise is to envision the negativity in any event so that it can be avoided. Inversion allows us to look at things in the opposite way. This can be particularly useful in solving complex problems, helping to see them in a different way. For example, the inverse of a simple addition would be subtraction from the total. The power of inverse thinking is a rare and crucial skill that all great thinkers use to their own advantage. Becoming successful—is the mantra of human ideology that dominates reality. Complimenting opposite of imagining success with imaging failure can give you a full picture before you make any decisions. Being positive and negative is complimentary. Avoiding failure is equally important in being successful.

**Stoics**: Stoics (early 3rd century BC)—followed the inversion process to eliminate the worst case scenario by thinking backwards and avoiding any failures. The ancient Stoic philosophers like Marcus Aurelius, Seneca, and Epictetus regularly conducted an exercise known as a *premeditatio malorum*, which translates to *premeditation of evils*. The goal of this exercise was to envision the negative things that could happen in life. For example, the Stoics would imagine what it would be like to lose their job and become homeless. Or to suffer an injury and become paralyzed. Or to have their reputation ruined and lose their status in society.

**Carl Jacaboi**: Carl Jacaboi (1804–1851) was a German mathematician, who made contributions to elliptic functions, dynamics, differential equations and number theory. These theories are still applicable in our modern age. How was Jacobi able to contribute so much to the scientific field during his career? He was known for his ability to solve complex problems by following a simple strategy—*Invert, always invert (man muss immer umkehren)*, conveying his belief that the solution of many hard problems can be clarified by re-stating them in an inverse form (reverse-engineer). He would write down the opposite of the problem he was trying to solve. By conducting this exercise he was able to resolve many theoretical problems.

**Subtractive knowledge**: Subtractive knowledge is when you envision negative things and then subtracting what is not important or what is wrong from the total. Additive measures manifest in form of an urge to do something about a problem which may not need any intervention. Subtractive measures adhere to the philosophy of *don’t try to fix something which ain’t broken.* Nassim Taleb also employs *subtractive epistemology*. He argues that the greatest and most robust contribution to learning and knowledge consists of removing what we think is wrong. What does not work, that is negative knowledge, is more robust than positive knowledge.

**Avoid stupidity**: Avoiding stupidity is another way to apply inversion in your life. It’s a choice between avoiding stupidity and seeking brilliance. You can avoid a bad marriage by being loyal to your significant other. Or in life, you can avoid death by staying away from alcohol and drugs. Another way to apply inversion is to not only find role models but also find anti-role models — people you don’t want to resemble when you grow up. You want to avoid the path they took. Ambitious young people can find a lot of success in this type of thinking.

**90 days**: Another great implementation of inversion was by the CTO of Pandora. Pandora faced immense competition from Spotify, Apple Music, Google, and Amazon. However, it still managed to stay alive despite the heavy competition. 90 days is the length of one quarter. That’s how far you can reasonably think and plan ahead when you’re in hyper-growth. He asks—“*And there’s a question you have to ask yourself at the start of every quarter: What would be stupid for us not to do in the next 90 days?*”

**Munger on inversion**: Charlie Munger is one of the greatest thinkers of the 21st century. Charlie Munger has adopted an approach to solving problems that is the reverse of the approach many people use in life. He avoids misery. Munger once gave a speech where he spoke about a famous Johnny Carson talk in which the comedian described all the ways one can be miserable. Munger is also commonly famous for saying “*Invert always invert.*”

> Think forwards and backwards — invert, always invert. Many hard problems are best solved when they are addressed backward. The way complex adaptive systems work and the way mental constructs work is that problems frequently get easier, I’d even say usually are easier to solve, if you turn them around in reverse. In other words, if you want to help India, the question you should ask is not “how can I help India,” it’s “what is doing the worst damage in India? What will automatically do the worst damage and how do I avoid it?” Figure out what you don’t want and avoid it and you’ll get what you do want. How can you best get what you want? The answer: Deserve what you want! How can it be any other way? The great Algebra pioneer Jacobi knew that it is in the nature of things that many hard problems are best solved when they are addressed backward. In life, unless you’re more gifted than Einstein, inversion will help you solve problems.

> Let me use a little inversion now. What will really fail in life? What do you want to avoid? Having a certain kind of temperament is more important than brains. You need to keep raw irrational emotion under control. When you have a huge convulsion, like a fire in this auditorium right now, you do get a lot of weird behavior. If you can be wise [during such times, you’ll profit]. It is remarkable how much long-term advantage [we] have gotten by trying to be consistently not stupid, instead of trying to be very intelligent.

 <br>
</details>
<br>

<details>
    <summary><strong>Compound interest</strong></summary>
    <br>

Compound interest is the interest you earn on the sum of your initial principal amount and the interest accumulated.

Think of it as a snowball effect. Snowball rolling down the hill, accumulating more snow and gaining in size. Snow keeps compounding as it accelerates downwards. The more you accumulate over a long period of time the faster it compounds whether with money or wisdom. Interest is the cost of borrowing or an income on a deposit. When money is lent, a simple interest is calculated on the original, principal sum. This is interest. Compound interest is calculated on the principal amount plus the accumulated interest of previous periods, and can thus be regarded as interest on interest. It is the result of reinvesting interest, rather than paying it out, so that interest in the next period is then earned on the principal sum plus previously accumulated interest. Compound interest is standard in finance and economics. The rate at which compound interest accrues depends on the frequency of compounding. The higher the number of compounding periods, the greater the effects of compounding.

> Compound interest is the eighth wonder of the world. He who understands it, earns it … he who doesn’t … pays it. ― *Albert Einstein*

What else compounds other than money and mathematical equations? Compound interest is well known in the field of modern finance but money is not the only thing that compounds. The power of compounding applies far beyond the realms of finance. Knowledge, relationships, marketing, sales or ideas are all compoundable. Even in sports. Score built on momentum can compound during the game. Knowledge compounds rapidly, as you read more, the more connections you can make across different ideas and fields, leading to a prosperous snowball effect. The more you do of something, the more it reinforces. You often get an advice to make daily improvements because it has long-term effects. That is called compounding. If you focus on improving 1% on daily basis, after a year, you'll be many times better than where you started. It can also have the opposite effect. As you decline 1% on a daily basis, you'll be far worse than where you started.

**Franceso Balducci Pegolotti**: Compound interest was once regarded as immoral and condemned by Roman law. In 1340, the Florentine merchant and politician, Franceso Balducci Pegolotti provided a table of compound interest in his book *Pratica della mercatura*. It gives the interest on 100 lire, for rates ranging from 1% to 8%, for up to 20 years.

**The Rule of 72**: The rule of 72 calculates the approximate time over which an investment will double at a given rate of return. 72 can be divided by the interest (*72/I*) to find out time it would take to double the initial amount. It can only be used for annual compounding. For example, let's say an investment that has a 6% annual rate of return will double in 12 years. An investment with an 8% annual rate of return will thus double in 9 years.

**Compounding is slow**: Compounding takes a long time which requires focus and dedication. Therefore, compounding is an exponential effect rather than a linear effect. We can visualize this by drawing out a hockey stick. Initially, it starts out slow and then it exponentially grows. If you don’t interrupt it, compounding produces a fortune. Compounding tiny excellence is what creates big excellence. So focus on compounding good habits and drain out the bad habits because focusing on bad habits can compound in the wrong direction and can turn out to be expensive.

 <br>
</details>

## Statistics
| Model | Definition | 
| -------------|:-------------:|
| _Regression to the mean_ | Periods of above averages are followed by below averages. |
| _Correlation and causation_ | Two things happening at the same time is correlation while one causing the other to change is causation. |
| _Theory of constraints_ | The theory of constraints answers a fundamental question of what is not working within a system. |
| _Central limit theorem_ | A large properly drawn sample will resemble the population from which it is drawn. |
| _Prisoner dilemma_ | Prisoner's dilemma helps us understand how people behave when it comes to cooperation or acting in their own self-interests. |
| _Marginal analysis_ | A cost benefit analysis which deals with an examination and identification of the added benefits of an activity weighed against the costs. |
| Law of large and small numbers| As a sample size grows large, its mean gets closer to the average of the population. A large sample size will give a more accurate outcome. |

<details>
    <summary><strong>Regression to the mean</strong></summary>
    <br>

Periods of above averages are followed by below averages.

If you throw twenty darts at a target and manage to hit the bull’s-eye eighteen times, the next time you throw twenty darts, it probably won’t go well. There is no scientific reasoning behind it, but rather a natural behavior of randomness. What goes up must come down and what goes down must come up. An anomaly in statistics (an extreme value), will tend to be closer to average the next time it is measured. If, when measured a second time, the value is found to be more extreme, then the original value was likely closer. “Regression” was discovered and named late in the nineteenth century by Sir Francis Galton, half cousin of Charles Darwin. Galton compared the height of children to that of their parents. He found that when the average height of the parents was greater than the mean of the population, the children were shorter than their parents. Likewise, when the average height of the parents was shorter than the population mean, the children were taller than their parents. Galton called this phenomenon regression toward mediocrity. Regression to the mean is a statistical phenomenon. It can result in wrongly concluding that an effect is due to a variable when it is due to a chance. Ignorance of the problem can lead to errors in daily decision-making process.

Mean is just another word for average. Regression to the mean explains why extreme events are usually followed by something more typical, regressing closer to the expected mean. For example, not every non-athletic swimmer can be expected to break records time after time.  A repeat of a rare result is equally as rare as its first occurrence, such that it shouldn’t be expected the next time. We should never assume results based on a smaller set of observations. A small sample tells us very little beyond that what happened was within the range of possible outcomes. While first impressions can be accurate, we should treat them with skepticism. More data can help us distinguish what is likely from what is an anomaly.

**Business & investing**: Regression to the mean is powerful in business and investing. Periods of above averages are followed by below averages and vice-versa. As Charlie Munger said in Poor Charlie’s Almanack:

> Mimicking the herd invites regression to the mean. — Charlie Munger

His investing partner Warren Buffett puts it in another way:

> Most people get interested in stocks when everyone else is. The time to get interested is when no one else is. You can’t buy what is popular and do well. — Warren Buffett

Jason Zweig who is a successful financial journalist at Wall Street Journal writes:

> My role, therefore, is to bet on regression to the mean even as most investors, and financial journalists, are betting against it. I try to talk readers out of chasing whatever is hot and, instead, to think about investing in what is not hot. Instead of pandering to investors’ own worst tendencies, I try to push back. My role is also to remind them constantly that knowing what not to do is much more important than what to do. Approximately 99% of the time, the single most important thing investors should do is absolutely nothing. — Jason Zweig

Peter Bevelin who is another notable and well respected investor shares his thoughts.

> Regression to the mean is not a natural law. Merely a statistical tendency. And it may take a long time before it happens. — Peter Bevelin

Michael Mauboussin is a researcher in the investing world.

> Understanding and using the phenomenon of reversion to the mean is essential in making sound predictions [decisions]… Reversion to the mean is most pronounced at the extremes, so the first lesson is to recognize that when you see extremely good or bad results, they are unlikely to continue that way. This doesn’t mean that good results will necessarily be followed by bad results, or vice versa, but rather that the next thing that happens will probably be closer to the average of all things that happen. — Michael Mauboussin

**Sports**: Regression to the mean can frequently be observed in sports. Let's take Michael Jordan for example, one of the best basketball players who has two talented sons, but nowhere near to Jordan's level. They were both talented, but didn't make it to the NBA. The same phenomenon is justified for individual performances via speculation. We ought to remember chance plays a big role. A pro-runner sprinting at a record mileage against heavy wind will lead to mediocre results. And an average athlete running in favor of heavy wind will lead to spectacular results. But when there is no wind, things will even out over time. Nassim Taleb observes in his book Fooled by Randomness:

> The ‘hot hand in basketball’ is another example of misperception of random sequences: It is very likely in a large sample of players for one of them to have an inordinately lengthy lucky streak. As a matter of fact it is very unlikely that an unspecified player somewhere doesn’t have an inordinately lengthy lucky streak. This is a manifestation of the mechanism called regression to the mean….in real life, the larger the deviation from the norm, the larger the probability of it coming from luck rather than skills…This can be easily verified in stories of very prominent people in trading rapidly reverting to obscurity, like the heroes I used to watch in trading rooms. — Nassim Taleb

**Correlation & regression**: Regression to the mean occurs whenever a nonrandom sample is selected from a population and two imperfectly correlated variables are measured. The less correlated the two variables, the larger the effect of regression to the mean. The more extreme the value from the population mean, the more room there is to regress to the mean. Galton figured out that correlation and regression are not two concepts and they are different perspectives of the same concept. The general rule is whenever the correlation between two scores is imperfect, there will be regression to the mean. More explanation from [Wikipedia](https://simple.wikipedia.org/wiki/Regression_toward_the_mean):

> Galton showed that the height of children from very short or very tall parents would move towards the average. In fact, in any situation where two variables are less than perfectly correlated, an exceptional score on one variable may not be matched by an equally exceptional score on the other variable. The imperfect correlation between parents and children (height is not entirely heritable) means that the distribution of heights of their children will be centered somewhere between the average of the parents and the average of the population as whole. Thus, any single child can be more extreme than the parents, but the odds are against it.

 <br>
</details>
<br>

<details>
    <summary><strong>Correlation and causation</strong></summary>
    <br>

Two things happening at the same time is correlation while one causing the other to change is causation.

The temperature of the earth has been warming over the years. The number of pirates has declined in that time. There is a correlation between the temperature rise and pirates declining, but the warming is not the cause of the decline. Correlation does not imply causation. Correlation is when two or more variables change together, but they are not the cause of the other change or changes. Causation is when two or more variables change and one of those variables is responsible for the other change of changes. Don't draw conclusions if something is correlated. Take time to find and understand the hidden factors. Correlation and causation are mostly misunderstood and often used interchangeably. They are both statistical terms which are important to understand to draw correct conclusions. Failure to do so influences illogical inferences.

**Correlation**: Correlation shows how strongly the pair of variables are linearly related and change together. It does not tell us *why* the relationship exists, but it just says the relationship exists. News media are good at this. Blindly consuming information can have negative consequences. It is upon us to uncover the underlying variables, finding more information and observing whether the variables are truly correlated or not. Correlation coefficient is used to measure how strongly or poorly variables are correlated. The correlation coefficient varies between -1 and 1.

**Causation**: Causation takes correlation far by indicating a variable causing other to change or vice-versa. This is called cause and effect. There are cases in which classifying a *cause* is difficult but a good study of causal relationships takes into account of randomized controlled factors. This minimizes bias. The precision of outcomes are indicated by providing their confidence intervals.

**Correlation does not cause causation**: *Correlation does not imply causation* is a common phrase in the field of statistics. This phrase refers to the inability to reach a cause-and-effect relationship between two variables on the basis of an observed correlation between the variables. In technical terms of logic, *implies* means there is a *sufficient condition for*. Statisticians often refer to this as *causation is not certain*. Where there is causation, there is correlation. Correlation is often used in concluding causation because it is a necessary condition, it is not a sufficient condition.

> We do not have knowledge of a thing until we have grasped its why, that is to say, its cause. — Aristotle

**Causal analysis**: Causal analysis is the field of experimental design and statistics pertaining to establishing cause and effect. For any two correlated events, A and B, their possible relationships include:

- A causes B (direct causation)
- B causes A (reverse causation)
- A and B are both caused by C (the common-causal variable)
- A causes B and B causes A (bidirectional or cyclic causation)
- There is no connection between A and B; the correlation is a coincidence.

Thus there can be no conclusion made regarding the *existence* or the *direction* of a cause-and-effect relationship only from the fact that A and B are correlated. Determining whether there is an actual cause-and-effect relationship requires further investigation, even when the relationship between *A* and *B* is statistically significant, a large effect size is observed or a large variance is explained.

**Illogical conclusions**: Following are examples of illogical conclusions:

- _Reverse causation_: B causes A where cause and effect are reversed**‍**
    - ‍Example 1: The faster that windmills are observed to rotate, the more wind is observed. Wind velocity does not imply that wind is caused by windmills. It is the other way around — wind doesn't need windmills, while windmills need to wind to rotate. Wind can be observed where there are no windmills.**‍**
    - Example 2: Children that watch a lot of TV are the most violent. Clearly, TV makes children more violent. This could easily be the other way round — violent children like watching more TV than less violent ones.

- _Third causation_: C causes both A and B where it asserts that A causes B when, in reality, A and B are both caused by C
    - Example 1: Sleeping with shoes on is strongly correlated with waking up with a headache. This prematurely concludes that sleeping with shoes on causes headache. A more logical explanation could be that both are caused by a third factor which is going to bed drunk which gives rise to a correlation.
    - Example 2: As ice cream sales increase, the rate of drowning deaths increases sharply. Therefore, ice cream consumption causes drowning. This example fails to consider that people tend to engage in water activities such as swimming during hot weather than winter weather. Ice cream happens to be consumed more during the summer months. The increased drowning deaths are not due to ice cream.

> One of the first things taught in introductory statistics textbooks is that correlation is not causation. It is also one of the first things forgotten. — Thomas Sowell

 <br>
</details>
<br>

<details>
    <summary><strong>Theory of constraints</strong></summary>
    <br>

The theory of constraints answers a fundamental question of what is not working within a system.

It helps answer the question of what to change. You cannot change something if you don't know what to change. The theory of constraints amplifies the idea of "a chain is no stronger than its weakest link." Great organizations understand their own vulnerability in order to fix the weakest link. The theory of constraints (TOC) is an organizational management paradigm that views any manageable system as being limited in achieving more of its goal by a very small number of constraints. There is always at least one constraint, and TOC helps identify the constraint to restructure the organization, so it can achieve its goals. The core principle is that there are not many but a few constraints within a system. The theory says that all elements within an organization are interconnected to achieve a common goal. It focuses on one leverage point instead of solving for many or all.  Constraints can be internal or external.

**History**: The theory of Constraints (TOC) is a body of knowledge and a manufacturing and management methodology that was developed from the late 1970s by Israeli physicist Dr. Eliyahu Goldratt. He describes in his book, [The Goal](https://www.amazon.com/Goal-Process-Ongoing-Improvement/dp/0884270610), is that the performance of any system is fundamentally limited by the output of the bottleneck. Thus, no change to the system will result in overall improvement unless that change addresses the bottleneck. 

> Any improvements made anywhere besides the bottleneck are an illusion. — Dr. Eliyahu Goldratt

> A Thinking Process that enables people to invent simple solutions to complex problems. — Dr. Eliyahu Goldratt

> An expert is not someone who gives you an answer, an expert is someone who asks you the right question. — Dr. Eliyahu Goldratt

**Constraint & bottleneck are not the same**: A constraint and bottleneck are not the same. It is critical to differentiate the two. Finding a constraint is a strategic initiative. It is a leverage point for a leadership team to identify. This is where value is created for customers, stakeholders and employees. A constraint is the bottleneck with the least capacity in the entire system, and it can be reasoned about as the “constraint” only once you decide to manage it. Whereas a bottleneck prevents a company to operate at its maximum capacity due to many reasons. A bottleneck is simply a resource that has more demand placed on it than capacity to delivery. 

**Five focusing steps**: Theory of constraints is based on the premise that the rate of goal achievement by a goal-oriented system (i.e., the system's throughput) is limited by at least one constraint. The argument is if there was nothing preventing a system from achieving higher throughput (i.e., more goal units in a unit of time), its throughput would be infinite—which is impossible in a real-life system. Only by increasing flow through the constraint can overall throughput be increased. Goldratt proposed five Theory of Constraints steps, known as the five focusing steps. Assuming the goal of a system has been articulated and its measurements defined, the steps are:
1. _Identify_ the system's constraint(s).
2. _Decide_ how to _exploit_ the system's constraint(s).
3. _Subordinate_ everything else to the above decision.
4. _Elevate_ the system's constraint(s).
5. _Warning!_ If in the previous steps a constraint has been broken, go back to step 1, but do not allow inertia to cause a system's constraint.

**In business**: The Theory of Constraints is especially important in business.
- It creates a _real connection_ between the economic and financial aspects of the business.
- It allows leadership to _focus_ on the critical aspects that determine business outcomes.
- It introduces _scientific thinking_ within an organization. The entire system needs to be considered in order to identify a constraint.
- It _systematizes_ entrepreneurial spirit within an organization.

It is important to note that we don’t need more effort, just effort applied more effectively. This is how TOC can help businesses grow over time. Therefore, to continuously increase a system’s output, iteratively identify and address the current constraint.

**Outside business**: Keep in mind, constraints can appear beyond business. It can appear in your own personal life? For example, what is the bottleneck that is stopping you from exercising? Asking this question you are addressing a constraint in your life. TOC can also apply within traffic congestion, both physical and network traffic. Popular sites are always solving for constraints to provide better user experience. Peter Bevelin, in his book Seeking Wisdom:

> Optimization of one variable may cause the whole system to work less efficiently. Why? The performance of most systems is constrained by the performance of its weakest link. A variable that limits the system from achieving its goal or optimum performance. An increase in production may for example be physically constrained by the production capacity on one of the machines. If one machine in a production line of two machines can produce 100 items and the second 90, the output is physically constrained by the second machine. When trying to improve the performance of a system, first find out the system’s key constraint(s)- which may be physical (capacity, material, the market) or non-physical (policies, rules, measurements) – and its cause and effect relationship with the system. Maybe the constraint is based on faulty assumptions that can be corrected. Then try to “strengthen” or change the weakest link. Watch out for other effects – wanted or unwanted – that pop up as a consequence. Always consider the effects on the whole system.

 <br>
</details>
<br>

<details>
    <summary><strong>Central limit theorem</strong></summary>
    <br>

A large properly drawn sample will resemble the population from which it is drawn. 

The central limit theorem (CLT) implies that, in a majority of situations, when you add independent random variables to a formula, the sum will tend toward a normal distribution. In other words, given a large enough sample size from a population, the mean of the sample will be representative of the mean of the population. The theorem also states that the distribution of the sample and whole population will be similar. As the number of variables grows, the variances will also tend toward a normal distribution. A reasonable sample size to apply the central limit theorem to is considered to be between 30 and 40 units. The central limit theorem (CLT) is considered to be one of the most powerful theorems in all of statistics and probability. The question is why does this mathematical pattern show up so much. The answer is that normal distributions come out of a process of averaging. The 3 major characteristics of central limit theorem are:

1. Generalize conclusions on the entire population based on the results from the sample population.
2. Sample size of 30 or more is enough for this theorem to take effect.
3. The distribution of sample mean will approach a normal distribution even though the underlying population does not have a normal distribution.

If the central limit theorem applies, calculating the mean value for each sample then building a distribution from those mean values should lead to a normal result. Using this theorem, you should be able to generalize conclusions about an entire population based on results found through analyzing a sample of the population. It is a powerful theorem because it allows you to make reasonable assumptions about a population regardless of what the initial distribution looks like. There are endless applications to this theorem, including hypothesis testing, confidence intervals, and estimation. Normal distributions show up everywhere. Human height is (approximately) normal. Intelligence, as measured by IQ, is normal. Measurement errors tend to be normally distributed. If you were to represent the central limit theorem using an example, you should consider rolling a die. The more times you roll the die, the more likely the distribution will tend toward a normal distribution. Generally, once you’ve rolled the die at least 30-40 times, you should see a relatively normal distribution of variables. Normal distributions are also known as bell curves or Gaussian functions. The central limit theorem shows that the average of your sample means will be the population mean as well. Considering this, you can see how the central limit theorem can be used to predict the characteristics of a population rather accurately. The central limit theorem is limited by the fact that you must have a sample size ranging from 30-40 units before the theorem can be applied.

**History**: The central limit theorem has seen many iterations over the course of time, with the first version of the theorem dating back to 1810. The modern form of this theorem wasn’t precisely stated until around 1920. Once the central limit theorem was established, a bridge was erected between classical and modern probability theories. The Dutch mathematician Henk Tijms on central limit theorem:

> The central limit theorem has an interesting history. The first version of this theorem was postulated by the French-born mathematician Abraham de Moivre who, in a remarkable article published in 1733, used the normal distribution to approximate the distribution of the number of heads resulting from many tosses of a fair coin. This finding was far ahead of its time, and was nearly forgotten until the famous French mathematician Pierre-Simon Laplace rescued it from obscurity in his monumental work Théorie analytique des probabilités, which was published in 1812. Laplace expanded De Moivre's finding by approximating the binomial distribution with the normal distribution. But as with De Moivre, Laplace's finding received little attention in his own time. It was not until the nineteenth century was at an end that the importance of the central limit theorem was discerned, when, in 1901, Russian mathematician Aleksandr Lyapunov defined it in general terms and proved precisely how it worked mathematically. Nowadays, the central limit theorem is considered to be the unofficial sovereign of probability theory.

**Charles Wheelan**: Charles Wheelan tries to teach basic concepts of central limit theorem in his book *Naked Statistics* which is a book on stats 101:

> Statistics don't lie, but the data behind them can because they can be faulty, misleading, or downright false.

> At times, statistics seems like magic. We are able to draw sweeping and powerful conclusions from relatively little data. Somehow we can gain meaningful insight into a presidential election by calling a mere one thousand American voters. We can test a hundred chicken breasts for salmonella at a poultry processing plant and conclude from that sample alone that the entire plant is safe or unsafe. Where does this extraordinary power to generalize come from? Much of it comes from the central limit theorem.

> One of the most common thresholds that researchers use for rejecting a null hypothesis is 5 percent, which is often written in decimal form: .05. This probability is known as significance level, and it represents the upper bound for the likelihood of observing some pattern of data if the null hypothesis were true.

> Obviously rejecting the null hypothesis at the .01 level (meaning that there is less than a 1 in 100 chance of observing a result in this range if the null hypothesis were true) carries more statistical heft than rejecting the null hypothesis at the .1 level (meaning that there is less than a 1 in 10 chance of observing a result in this range if the null hypothesis were true).

> When you go to the doctor to get tested for some disease, the null hypothesis is that you do not have that disease. If the lab results can be used to reject the null hypothesis, then you are said to test positive. And if you test positive but are not really sick, then it’s a false positive.

> Doctors and patients are willing to tolerate a fair number of Type 1 errors (false positives) in order to avoid the possibility of a Type 2 error (missing a cancer diagnosis).

> Some classrooms had answer sheets on which the number of wrong-to-right erasures were twenty to fifty standard deviations above the state norm. (To put this in perspective, remember that most observations in a distribution typically fall within two standard deviations of the mean.) So how likely was it that Atlanta students happened to erase massive numbers of wrong answers and replace them with correct answers just a matter of chance? The official who analyzed the data described the probability of the Atlanta pattern occurring without cheating as roughly equal to the chance of having 70,000 people show up for a football game at the Georgia Dome who all happen to be over seven feet tall. Could it happen? Yes. Is it likely? Not so much.

**Education**: Students can apply the central limit theorem to make observations about social circumstances, group activities, and their own academic success. Using the central limit theorem, you can determine what outcomes are attainable for you compared to your peers. For example, if a majority of your classmates are failing Algebra, and you aren’t, there is a chance that a curve will be applied to make the grading system more balanced. The teacher may also add in additional variables, such as extra credit assignments and pop quizzes, to offer the other students more opportunities to pass the class. Through the central limit theorem, you can assume that those additional assignments add new variables to the grading formula and that those variables will normalize across the distribution and allow some students to improve their grades. Though, if you perform poorly on those assignments, your high grade could be lowered toward the mean distribution.

**Business & investing**: Businesses can use the central limit theorem to make observations about the market, their business itself, and more. With this theorem, business leaders can determine what their target audience likes, what they don’t like, and how to reach them effectively. That’s only one way the central limit theorem can be applied to business. The same applies to understanding the normal distribution of investment results of various stocks.

**Limitation**: The normal distribution is a pretty user-friendly mental model when we are trying to interpret the statistical metrics like mean and standard deviation. However, it may be misleading model. One limitation on normal distribution is that it is always assumed that the underlying population also has a normal distribution which might not be true due to infinite variables. Second *average* is heavily skewed by outliers.

R.C. Geary in his paper [“Testing for normality”](https://doi.org/10.1093/biomet/34.3-4.209) in 1947:

> Normality is a myth; there never was, and never will be, a normal distribution.

In [Statistics for Dummies](https://www.dummies.com/article/academics-the-arts/math/statistics/how-the-central-limit-theorem-is-used-in-statistics-169776):

> The Central Limit Theorem (CLT for short) basically says that for non-normal data, the distribution of the sample means has an approximate normal distribution, no matter what the distribution of the original data looks like, as long as the sample size is large enough (usually at least 30) and all samples have the same size.

Nassim Nicholas Taleb in his book *The Black Swan* argues, we tend to see events that are in the extreme tail ends more often than we would by normal distributions, and so this gives us too much confidence that rare “black swan” events are statistically impossible.

> A theory is like medicine or government: often useless, sometimes necessary, always self-serving and, on occasion, lethal. It needs to be used with care, moderation and close adult supervision.

 <br>
</details>
<br>

<details>
    <summary><strong>Prisoner dilemma</strong></summary>
    <br>

Prisoner's dilemma helps us understand how people behave when it comes to cooperation or acting in their own self-interests.

Imagine two prisoners are given two choices: confess or do not confess. If they both confess, they each get 2 years in prison. If neither of them confesses, they each get 1 year. If one prisoner confesses and the other does not, the confessor goes free and the other gets 3 years.  Neither prisoner knows whether the other has confessed because they cannot communicate with one another. Therefore, it is in the self-interest of each to confess. When each prisoner pursues his or her self-interest, both end up worse off than if they would have cooperated.  Arms race between powerful nations is a perfect scenario of prisoner's dilemma.  Powerful nations like US, China and Russia keep manufacturing weapons. However, both countries are better off when they cooperate and avoid an arms race. Yet each nation pursues self-interest of becoming the most powerful nation.

A game in which two separate prisoners are given two choices: confess or don't confess. The prisoner's dilemma is a paradox in decision analysis in which two individuals acting in their own self-interests do not produce the optimal outcome. The typical prisoner's dilemma is set up in such a way that both parties choose to protect themselves at the expense of the other participant. As a result, both participants find themselves in a worse state than if they would have co-operated with each other. The highest reward for the prisoner occurs when both parties choose to co-operate. It was originally framed by Merrill Flood and Melvin Dresher while working at Rand Corporation (RAND) in 1950. Albert W. Tucker, an American mathematician formalized the game with prison sentence rewards and named it “prisoner's dilemma.” The title “prisoner's dilemma” and the version with prison sentences as payoffs are due to Albert Tucker, who wanted to make Flood and Dresher's ideas more accessible to an audience of Stanford psychologists. The prisoner's dilemma is one of the most well-known concepts of game theory in social science.

**Game theory**: Game theory is the logical analysis of game (situation) of conflict and cooperation when there are at least two players (parties) involved. Each player takes courses of action to determine the outcome of a game. Game theory is the study of how players should rationally play games. Each player would like the game to end in an outcome which gives him or her as large a payoff as possible.

**The dilemma of prisoners**: Prisoner's dilemma is a classic example of game theory. The prisoner's dilemma is the best-known game of strategy in social science. It helps us understand what governs the balance between cooperation and competition (self-interest) within people, companies (business), nations (politics) or even biological species (social environment). Will the so called “prisoners” choose to betray, confess or remain silent? 

**Nash equilibrium**: In the prisoner’s dilemma the Nash equilibrium is for both prisoners to confess since neither prisoner will then have the unilateral ability to increase their outcome. A Nash equilibrium **is reached when the choices of all players leads to a situation in which there is no other choice that makes any other player better off. In other words, cooperate with one another to reach the optimal outcome. However, the rational choices are never made. So, this begs the following question? Can we teach players (prisoners) to make rational decisions?

**Escape from the dilemma**: Over time, players can learn to overcome individual incentives in favor of common good by repeatedly playing the game. For every iteration, players get rewarded for co-operation and punished for self-interest. Players then would learn that they do best when both act unselfishly and cooperate.  If one player failed to cooperate in one game, the other player could retaliate by not cooperating in the next game, and both would lose until they would have co-operated again. When the game is repeated a fixed number of times, however, this argument fails.

**Limitations**: To see the argument mentioned above, take two businesses competing for 10 days before Christmas. Both players maintain fair prices because if one doesn't, the competitor will retaliate next day. However, on the last day, one player decides not to honor fair prices and the competitor loses out because the next day people are no longer shopping and busy spending time with their family on Christmas Day. Knowing this, the business losing out has no incentive to offer fair prices. It is a fair conclusion to make rational business will engage in a price war every day since both player knows the game being played fixed number of times.

**Business**: The dilemma in business.

> Over the years, we had the option of making large capital expenditures in the textile operation that would have allowed us to somewhat reduce variable costs. Each proposal to do so looked like an immediate winner. Measured by standard return-on-investment tests, in fact, these proposals usually promised greater economic benefits than would have resulted from comparable expenditures in our highly-profitable candy and newspaper businesses. But the promised benefits from these textile investments were illusory. Many of our competitors, both domestic and foreign, were stepping up to the same kind of expenditures and, once enough companies did so, their reduced costs became the baseline for reduced prices industry-wide. Viewed individually, each company’s capital investment decision appeared cost-effective and rational; viewed collectively, the decisions neutralized each other and were irrational (just as happens when each person watching a parade decides he can see a little better if he stands on tiptoes). After each round of investment, all the players had more money in the game and returns remained anemic. — Warren Buffett

> How a firm interacts with other firms plays an important role in shaping sustainable value creation. Here we not only consider how many companies interact with their competitors, but how companies can co-evolve. Game Theory is one of the best tools to understand interaction. Game Theory forces managers to put themselves in the shoes of other players rather than viewing games solely from their own perspective.The classic two-player example of game theory is the prisoners’ dilemma. — Michael J. Mauboussin

 <br>
</details>
<br>

<details>
    <summary><strong>Marginal analysis</strong></summary>
    <br>

A cost benefit analysis which deals with an examination and identification of the added benefits of an activity weighed against the costss.

Seth Godin has a great definition on marginal cost:

> The cost of the next item produced is called ‘marginal cost‘. It doesn’t include set-up fees, rent, years of training, insurance or all the other huge costs an organization might pay. It’s merely the cost of one more unit.

Marginal does not mean average. The additional benefit per unit can have huge impact upwards or downwards. This is why high scale growth can be good or bad. Paul Heyne who was a well known economist of his time, shares his thoughts on marginal vs average:

> It is important to distinguish between average and marginal. A manufacturer’s average cost of producing automobiles (which would be the total cost of production divided by the total number of cars the manufacturer produces) may be $25,000, but the marginal cost of producing an additional automobile (or an additional 1,000 automobiles) might be much lower, say, $10,000 per car. Costs associated with research, testing, design, molds, heavy equipment, and similar factors of production must be incurred whether the manufacturer is going to produce 1,000 units, 10,000 units, or 100,000 units. Such costs will clearly contribute to the average cost of an automobile, but they will change very little as additional units are produced. Thus, the marginal cost of additional units may be substantially less than the average cost. Should production be expanded or reduced? That choice should be based on marginal costs, which indicate the change in total cost due to the decision.

Munger once described airlines industry as “marginal cost with wings”.

> Over the years, we’ve tried to figure out why the competition in some markets gets sort of rational from the investor’s point of view so that the shareholders do well, and in other markets, there’s destructive competition that destroys shareholder wealth. If it’s a pure commodity like airline seats, you can understand why no one makes any money. As we sit here, just think of what airlines have given to the world—safe travel, greater experience, time with your loved ones, you name it. Yet, the net amount of money that’s been made by the shareholders of airlines since Kitty Hawk, is now a negative figure—a substantial negative figure. Competition was so intense that, once it was unleashed by deregulation, it ravaged shareholder wealth in the airline business.

Marginal analysis can be used to analyze information consumption. Some might call it knowledge. There is a marginal return to information, and it often reaches zero, or even negative. The marginal return of information is the relationship between a “unit” increase in information and the value created by that new knowledge. A student who has never read a book on Computer Science, but picks it up for the first time, the marginal value of information is high. However with every additional textbook on Computer Science, there are diminishing returns to be seen. The marginal value of each additional textbook gets smaller and smaller. Understanding this ensures there are downside to consuming more.

Marginal analysis is of great relevance in healthcare. One would think, the more healthcare is consumed, the higher the level of health. However, it is likely that if someone has poor levels of health, health care has more impact on health than when they are healthy. There is plenty written on this topic. The usefulness of marginal analysis as a tool can be used to understand historical health care spending patterns while assessing the marginal benefit of care.

Consider social media or e-commerce platforms. Each additional user increases network effect while additional cost is almost zero. There are many other applications to employ this tool.
 <br>
</details>
<br>

<details>
    <summary><strong>Law of large and small numbers</strong></summary>
    <br>

As a sample size grows large, its mean gets closer to the average of the population. A large sample size will give a more accurate outcome.

The law of small numbers refers to the incorrect belief held by experts and laypeople alike that small samples ought to resemble the population from which they are drawn. Although this is true of large samples, it isn’t for small ones. So the “law” of small numbers isn’t really a law at all, but a fallacy.

Law of large numbers: The law of large numbers states that the proportion of results will tend toward an expected value as the number of trials increases. With large numbers, you can expect that proportion to be very close to the expected value of the process. This is basically what makes much of the field of statistics (and, by extension, science) work.

Law of small numbers: The law of small numbers is a mistake in thinking. You might take a small sample and assume that what you observe there is true for the broad population. This cognitive fallacy goes by other names such as "generalization from the particular", or just "leaping to a conclusion", and traders do it all the time.

Daniel Kahneman’s book _Thinking, Fast and Slow_ points out that researchers have their own bias–the law of small numbers. Is this bias to blame for many modern day myths? It’s a general bias that makes people favor certainty over doubt. 

Most people, including many experts, don’t appreciate how research based upon small numbers or small populations can often generate extreme observations. As a result people have a tendency to believe that a relatively small number of observations will closely reflect the general population. This is reinforced by a common misconception that random numbers don’t generate patterns or form clusters. In reality they often do. Kahneman makes the observation: “We are far too willing to reject the belief that much of what we see in life is random.” 

Kahneman acknowledges that researchers (social and behavioral scientists) have too much faith in what they learn from a few observations:

- They select too small a sample size which leaves their results subject to a potentially large sampling error.
- Experts don’t pay enough attention to calculating the required sample size and instead use rules of thumb.

Kahneman’s work raises some important questions for researchers and customer insight specialists.

- We are pattern seekers, and we often use small samples in qualitative research and usability testing. However, is there a tendency to extrapolate the findings from small scale studies to the wider population?
- Do researchers sometimes select too small a sample size in quantitative studies and experiments? Is this because they use a rule of thumb rather than calculating the statistically required sample size?
- Are we too quick to reject a random process as being truly random?

As with all cognitive biases, you can't fix this. It's a fundamental part of how humans think and process information. (And from an evolutionary perspective, there was probably a benefit.) What you need to do is to be aware of it. Think about how this bias might impact your perception of data, and then work to counteract it.

- Cultivate the skill of thinking in large sample sizes. Don't pay too much attention to the outcome of any one trade.
- Be aware of how emotional flags can (often, falsely) highlight certain events. For instance, if you're thinking about your last 30 trades, you might find yourself focusing in on 2 or 3 that were quick losses, wondering what you could have done better in those trades. Sometimes, this is justified, but often it is just noise in the data.
- Always ask “Am I sure?” and “What am I missing?” Become obsessive with your focus on these questions and honest with your answers. (Hint: The right answers to those questions are almost always “No” and “I might not know what I'm missing”!) Simply thinking around the corners like this will separate you from the mass of struggling traders who never dare face such hard questions.

 <br>
</details>

## Economics
| Model | Definition | 
| -------------|:-------------:|
| _Pareto principle_ | 80% of the outcomes come from 20% of the action. |
| _Tradeoffs_ | A giving up of one thing in return for another to produce the most desirable outcome. |
| _Tragedy of commons_ | When a set of individuals act in their own self-interest by depleting common resources. |
| _Competitive advantage_ | Competitive advantage is the leverage a business has over its competitors. |
| _Wealth effect_ | The wealth effect reflects the effect that rising wealth has on consumer confidence. |
| _Creative destruction_ | Outdated product replaced by new ones due to innovation. |

<details>
    <summary><strong>Pareto principle</strong></summary>
    <br>

80% of the outcomes come from 20% of the action.

Everyone has that favorite shirt in their closest which they wear 80% of the time. This is the essence of Pareto Principle. The smart thing to identify is what 20% of things in life drive 80% of the results. For many events, it can be shown that 80% of the effects come from 20% of the causes. Inputs are not directly relative to outputs. In business, 80% of revenue generally comes from 20% of the clients. This principle can help to show where to focus time and energy. The Pareto Principle also known as the *80/20* is an incredible helpful mental model to add it to your thinking toolbox. In a world where you are constantly bombarded with information, the Pareto Principle can help you make the right choices by shifting your focus and energy on tasks that would produce the most results. It is important to remember that there are only so many minutes in an hour, hours in a day, and days in a week. Pareto Principle can help you see that this is a good thing; otherwise, you’d have a never-ending list of things to do. So, you must always ask — what 20% of your work can drive 80% of the outcomes?

**Vilfredo Damaso Pareto**: The Pareto Principle was founded by Vilfredo Damaso Pareto, an Italian economist in 1896. Pareto, an amateur gardener, noticed one day that 20% of the pea plants generated 80% of the healthy pea pods. This observation led him to think about uneven distribution. He observed this same principle elsewhere. For example, he also realized in Italy where he lived, 80% of the land was owned by 20% of the people. He further investigated different industries and found that 80% of production typically came from 20% of the companies. This generalization became the Pareto Principle.

**Not a law**: Let’s also clarify the limitations of the Pareto Principle. While the 80/20 split is true for Pareto’s observation, that doesn’t necessarily mean that it always has to equal 100. For instance, 30 percent of employees can complete 60 percent of the total tasks. The remaining employees may not be as productive or may be slacking off on the job. This further reiterates that the Pareto Principle is merely an observation and not necessarily a law. With any mental model, it is important not to over apply it. The biggest takeaway the Pareto principle provides is the idea that most things in life are not distributed evenly. While you should be seeking to invest your time in the highest output activities, the fact remains that for many things, you canʼt just do 20% of the work for 80% of the result. Sometimes you need to grind out the last 20% — even if you are suffering diminishing returns — to get the job done. Building 80% of a car isnʼt the best strategy, nor is completing 80% of your research paper. Paretoʼs principle is a useful construct when analyzing efforts and outcomes. It can provide a useful framework for addressing many problems. It should be used liberally, but you should not forget that 20 percent is a general observation.

 <br>
</details>
<br>

<details>
    <summary><strong>Tradeoffs</strong></summary>
    <br>

A giving up of one thing in return for another to produce the most desirable outcome.

Teaching the tradeoff between short- and long-term gains often comes to play during parenting. Try this experiment: put a marshmallow in front of a child, tell her that she can have a second one if she can go 15 minutes without eating the first one, and then leave the room. Every decision has tradeoffs: when you choose to do one thing it means you choose not do other thing. Certain situations have two or more desirable outcomes. There are times when all outcomes cannot be achieved together: there will be losses and gains with each. You need to find the trade-off which will produce the most desirable outcome.

> There are no solutions. There are only trade-offs. — Thomas Sowell

> Economics teaches you that making a choice means giving up something. — Russ Roberts

> Strategy is about making choices, trade-offs; it's about deliberately choosing to be different. — Michael Porter

The value of what we have to give up in order to choose something else. As with any other cost, the goal is to minimize it. Opportunity costs are very real. A central component of economics is the time value of money which means that money today is worth more than money in the future. Economically, this relationship is entirely based on opportunity costs. In situational decisions, something has to give. In other words, a trade-off is when one thing increases, the other must decrease. For example, a full room of objects can fit only a certain volume of things. In order to fit more in, something has to be removed. Limitation like this are known in many disciplines such as physics, economics and biology. This comes handy in making strategic decisions. It's a tactic that many leaders use. For instance, should an energy company continue to produce more oil to support world's demand while damaging the environment? Or, should it introduce greener technology? But will have to bear more risk because it might not lose money because a reliable green technology does not exist yet at a larger scale. These type of examples are commonly asked when leaders make decisions. Each decision has an advantage and disadvantage. The one which has the least disadvantage and the most advantage is the one a leader should make.

- Should you invest in a bond or a stock?
- Should you go to school or not?
- Should you study engineering or art?
- Should you buy a small fuel-efficient car or a large fuel-inefficient car?
- Should you work long hours or short hours?
- Should you work more or spend time with kids?
- Should you cook at home to save money or eat out?

We often wrestle with these types of trade-offs. These aren't easy decisions to make, and therefore we avoid them.  We can only pick one side so focusing on which one rewards the most is where we should spend our energy. Making sacrifices is normal during trade-offs.

> Winners embrace hard work. They love the discipline of it, the trade-off they're making to win. Losers, on the other hand, see it as punishment. And that's the difference. — Lou Holtz

When we choose to optimize a choice, it means we are sub-optimizing another choice.

 <br>
</details>
<br>

<details>
    <summary><strong>Tragedy of commons</strong></summary>
    <br>

When a set of individuals act in their own self-interest by depleting common resources.

Fisheries provide the classic example of the tragedy of the commons. Fishing too much for seafood leads to depletion of fishes from our ocean. The ‘tragedy’ refers to a set of individuals who, acting rationally, independently, and in their own self-interest can create a situation where they destroy a group’s collective long-term viability by depleting a common source. Fishing and herding are classic examples. The theory was originated in 1833 by the British economist William Forster Llyoyd in his essay, who used a hypothetical example of the effects of unregulated grazing on common land in Great Britain and Ireland. The concept became widely known as the “tragedy of the common” over a century later due to an article written by American biologist and philosopher Garrett Hardin in 1968. In our modern economic times, “commons” means any shared and unregulated resource such as atmosphere, oceans, rivers, fish stocks, roads and highways, or even an office refrigerator. The term is used in environmental science. The “tragedy of the common” is often cited in connection with sustainable development, meshing economic growth and environmental protection, as well as in the debate over global warming. It has also been used in analyzing behavior in the fields of economics, evolutionary psychology, anthropology, game theory, politics, taxation and sociology.

**Garrett Hardin**: Hardin wrote *The Tragedy of the Commons* in 1968, at the height of the Cold War and U.S. arms race with the Union of Soviet Socialist Republics (USSR) for domination through lethal weapons. Technology got the countries into the situation, and Hardin believes relying on more technology will only make the situation deadlier. He opens the essay with an appeal to look for alternate kinds of solutions to other problems as well.

> The oceans of the world continue to suffer from ... the philosophy of the commons. — Garrett Hardin

Hardin is opposed to shared resources being available for every member to use without limit. He believes a resource can only be shared when the user population is small and use is low. The Declaration of Human Rights was adopted in the aftermath of the atrocities of World War II. It states a person is entitled to an adequate standard of living, including food, clothing, housing and medical care and necessary social services, and the right to security in the event of unemployment, sickness, disability, widowhood, old age or other lack of livelihood in circumstances beyond his control. It also states each individual has the right to decide how many children to have. Hardin objects to the declaration because it sanctifies the rights of families to make their own decisions outside state control and supports the creation of a welfare state.

Hardin objects to the welfare state, where society or government provides food, shelter, and social services to the needy. In Hardin's view these entitlements protect people from the negative consequences of their own actions, especially in regard to having children they can't afford. The society is left responsible for providing for their children. Hardin favors private ownership, which protects a resource from overuse. Since it is not commons, it is protected from being overrun and exploited by others. However, Hardin admits a property owner or inheritor can also squander the resource or use it irresponsibility. According to Hardin, the earth's oceans and all they hold are viewed as an unlimited commodity to be exploited. For millennia fish were caught in small enough numbers, but in modern times demand for seafood has made fishing a profitable industry. This has led to overfishing and the near extinction of whales and other sea life. 

In *The Wealth of Nations* (1776), economist Adam Smith developed the idea individuals making rational choices on their own behalf ultimately benefiting society. Someone who "intends only his own gain," Smith argued, is "led by an invisible hand to promote ... the public interest." Competition forces individuals and businesses to continually make their products more attractive in price or function. As a result, products keep improving. Society benefits and the economy grows. Garret Hardin revised the theory later to account for “managed” in addressing to fix the tragedy of the commons. That is done when regulations, tax and public policies are in place to effectively manage the common resources.

> A ‘managed commons’ describes either socialism or the privatism of free enterprise. Either one may work; either one may fail: ‘The devil is in the details.’ But with an unmanaged commons, you can forget about the devil: As overuse of resources reduces carrying capacity, ruin is inevitable.

**How to solve?**: The government can solve the tragedy of the commons in two ways.

1. Reduce the usage of common resource through regulation or taxes.
2. Turn the common resource into a private good.

> What is common to many is taken least care of, for all men have greater regard for what is their own than for what they possess in common with others. — Aristotle

Singapore is the 3rd most densely populated country in the world. Roads are limited. If everyone uses the car, traffic becomes the problem. So, government made driving license very expensive. Second, if cars are driven during peak traffic, the toll would cost more. Singapore's government discouraged driving and aligned incentives for people to behave accordingly. People started using public transportation for their commute and this in turn helped to resolve the tragedy of the commons.

 <br>
</details>
<br>

<details>
    <summary><strong>Competitive advantage</strong></summary>
    <br>

Competitive advantage is the leverage a business has over its competitors.

A situation wherein one party has significantly more experience, knowledge, or resources than a competitor. In business, a competitive advantage is the attribute that allows an organization to outperform its competitors. A competitive advantage may include access to natural resources such as high-grade ores or a low-cost power source, highly skilled labor, geographic location, high entry barriers, and access to new technology. To maintain a competitive advantage, you must constantly assess your mental models and improve them when possible. By properly organizing your cognitive resources, you can position yourself better in the world and find greater success. One way to gain a competitive advantage is by learning how to learn faster than other people. This will allow you to develop new skills and knowledge exponentially faster than others.

**Warfare**: Consider this excerpt from a *Future War Paper* titled *[Sustaining Competitive Advantage: Mental Models and Organizational Learning for Future Marines](https://apps.dtic.mil/dtic/tr/fulltext/u2/a505425.pdf)*:

> Napoleon shocked the Prussians at Jena. The Prussian generals could not conceive of an entity capable of defeating the system designed by Frederick the Great. Wedded to a scheme that brought them past successes, the Prussians were unable to see the new conditions confronting them. The Prussians never fully recognized the true extent of the mental rigidity and deterioration afflicting the generals until that October afternoon in 1806, at Jena and Auersted. The Prussian generals did not see what was happening in the world around them because their collective frame of mind would not allow new ideas to intrude. This historical example – and countless others like it – includes the elements of change and an inability to perceive change.

> So why were the Prussians, among many others, unable to recognize change and then successfully adapt?...The answers lie in mental models and organizational learning. They explain how people make sense of and act in the world, and how organizations learn and adapt to achieve winning results.

When planning your strategy, show a preference for paths that are best suited for someone with your distinct knowledge and resources. Creating a pattern of habits that allow you to navigate that path is the key to maintaining your competitive advantage after acquiring it. 

> To a certain extent, you can predict the outcomes of events that you have significant knowledge of. Therefore, someone who has a competitive advantage is effectively someone who can see a of the bigger picture that is not apparent to the rest of the audience. With more information on hand, they are better equipped than their competitors, allowing them the opportunity to achieve greater success at potentially faster speeds than those who contest them.

**Competition in business**: Knowing mental models can have huge competitive advantage in business. They have been influential in strategic thinking. They have a [shaping effect](https://www.anzam.org/wp-content/uploads/pdf-manager/1030_ANZAM2009-086.PDF) on long-term, analytical and creative thinking. Competition is a cornerstone o business, and competitive advantage has been documented in some form for centuries. Historically, a competitive advantage could readily be seen in businesses that decided to build their stores in locations that later became heavily trafficked. For businesses in most industries during the mid 19th century, the location of your business was critically important. If you opened a bar in the middle of the town’s business district, then your odds of success were much greater. A bar located 25 miles outside of town wouldn’t fare quite nearly as well under typical circumstances. In those days, opportunities to gain a competitive advantage were rare, and companies that could retain such an advantage for an extended period were unheard of. As technology continued to advance, it became easier for people to innovate, making a competitive advantage much easier to gain for the average individual. Today, there are countless avenues through which people and organizations can gain a competitive advantage.

**How to develop a competitive advantage?** Michael Porter, a professor at Harvard Business School, wrote a book in 1985 which identified three strategies that businesses can use to tackle competition. These approaches can be applied to all businesses whether they are product-based or service-based. He called these approaches generic strategies. They include *cost leadership*, *differentiation*, and *focus*. These strategies have been created to improve and gain a competitive advantage over competitors. These strategies can also be recognized as the comparative advantage and the differential advantage. There is no precise method of acquiring a competitive advantage, though, in the realm of business some would suggest that the advantage goes to whoever can provide the greatest value, at the lowest expense.

It should also be noted that there is a difference between competitive advantage and sustained competitive advantage. To develop a competitive advantage, you must position yourself in a place where few others go, providing you access to a unique vantage point that puts you into a position of great strategic importance. On the other hand, sustaining a competitive advantage requires well-timed adaptation to the world as it changes. By developing a competitive advantage in multiple fields, then sustaining them all at once, you can create a situation where the sum value of each is actually greater than the whole. Each area where you hold competitive advantage impacts another, allowing you to amplify your effectiveness in all areas by improving yourself in just a single discipline.

**Sustainable sources of competitive advantage**: According to [Morgan Housel](https://www.collaborativefund.com/blog/sustainable-sources-of-competitive-advantage/), the key to business and investing isn't finding an advantage but finding a sustainable sources of advantage. 

> Finding something others can’t do is nearly impossible. Intelligence is not a sustainable source of competitive advantage because the world is full of smart people, and a lot of what used to count as intelligence is now automated. That leaves doing something others aren’t willing to do as the top source of sustainable competitive advantage.

According to him, there are 5 sources of sustainable competitive advantage:

1. The ability to learn faster than your competition
2. The ability to empathize with customers more than your competition.
3. The ability to communicate more effectively than your competition.
4. The willingness to fail more than your competition.
5. The willingness to wait longer than your competition.

**What kills competitive advantage?** Sears made more profit in 1954 than its market cap in the decade it died. More than 40% of all public companies lose their value. So what kills the competitive advantage?

> Being right is the enemy of staying right because it leads you to forget the way the world works. – Jason Zweig

Beginner's mind in Buddhism unburdens past preconceptions. It is an active openness to trying new things and studying new ideas. Being locked into a single view is fatal in today's world in maintaining competitive advantage. Morgan Housel has [written](https://www.collaborativefund.com/blog/why-competitive-advantages-die/) more on why big winners falling off the podium when competitive advantage dies.

 <br>
</details>
<br>

<details>
    <summary><strong>Wealth effect</strong></summary>
    <br>

The wealth effect reflects the effect that rising wealth has on consumer confidence.

This behavioral economic theory suggests that as the value of a person’s assets rises, so does their rate of spending. This theory relies on the idea that consumers who earn more will feel more financially secure and confident about their wealth. As they begin to feel richer, the guilt associated with irresponsible spending often fades. Understanding the wealth effect has helped generations of consumers monitor and moderate their own spending. The wealth effect reflects the effect that rising wealth has on consumer confidence. Consumer confidence is the feeling of security that consumers feel when the value of their investments grows. Quite often, a boost in confidence leads to higher spending and less saving.

**Higher home values**: Increased spending has also been linked to higher home values. Many economists believe that housing wealth does indeed encourage extra spending, but there are some who dispute this theory, claiming that previous research on the subject has been overstated. In the paper, [Comparing Wealth Effects](http://www.econ.yale.edu/~shiller/pubs/p1181.pdf), Karl Case and Robert Shiller, the developers of the Case-Shiller home price indices, collaborated with John Quigley to research the wealth effect from 1982 to 1999. Their findings showed ‘weak’ evidence that variations in housing market wealth have important effects upon consumption. The study was later expanded to observe a 37-year period from 1975 to the second quarter of 2012. The results of this expanded data set revealed that an increase in housing wealth would boost household spending by around 4.3% over the course of four years. Likewise, a drop such as the fall in housing wealth caused by the crash between 2005 and 2009 would cause a spending drop of approximately 3.5%.

**Increase in stock value**: According to QZ, an online publication, only about 30% of Americans owned any form of stock in 1990. As of 2020, more than 50% now own stock. The 50% who don’t own stock are typically low-income Americans who don’t have access to retirement accounts. With approximately half of the population holding stock, it’s apparent that local economies may be sensitive to stock market performance. The National Bureau of Economic research argued this point in a paper published in 2019. Their research found that for every dollar of stock market wealth created, people spend 2.8 cents more per year. When this model is applied at the grand economic scale, it’s apparent that the wealth effect can predict higher wages and lower unemployment in a population. Events in 1968 highlight a real-world example of the wealth effect in action. The stock market entered a bull run, causing a massive rise in wealth amongst several specific categories of people. At the time, taxes were hiked by an additional 10%, yet people continued spending more in spite of this. Consumers were making more money due to the growth of the stock market, so the additional tax burden wasn’t of enough significance to impact their spending habits.

**Income effect & substitute effect**: Some critics even claim that increased asset wealth shouldn’t have as much impact on consumer spending as other factors, like taxes, household expenses, and employment trends. This argument is founded upon an assumption that an increase in the value of an investor’s portfolio doesn’t necessarily equate to an increase in disposable income. A change to one’s circumstances shouldn’t always change their consumption patterns, but the substitution effect shows that the inverse occurs quite commonly. There are two other effects that relate to the wealth effect: the income effect and the substitution effect. The income effect defines any change in the consumption of goods based on income and it can be expressed either directly or indirectly. When a consumer replaces cheap items with more expensive ones after experiencing a change in finances, they are acting out the substitution effect.

**The income effect in practice**:
When a consumer changes the way they spend because their income has changed, that would be a direct impact of the income effect. Indirect income effect would look like someone changing magazine subscriptions because they’ve recently gotten too old to read anything with “Teen” in the title. In this instance, your income has nothing to do with your decision. Rather, the decision is driven purely by a change in your literary tastes.

**The substitution effect in practice**: An example of the substitution effect can be found in a situation where someone’s business grows quickly, so they decide to upgrade systems that were already updated recently. The additional purchase isn’t necessary, but the negative consequences are disregarded due to the additional income that’s available.

**Wealth effect in business & education**: The wealth effect, and income effect, could be seen in businesses that experience a period of high profits, then use their increased revenue to expand into new locations. With more wealth on hand, business leaders are typically more comfortable spending on important resources like labor, production, and marketing. When companies outsource their operations to an outside organization, they are applying the substitution effect. Because they can get the same work done at a lower cost or in a shorter time using an outside provider, they substitute in a more effective solution. This effect also applies to learning. When one feels they have accumulated significant knowledge, they are more likely to pursue riskier educational pursuits. They have a wealth of knowledge, therefore it is no issue to spend time learning a difficult subject.

 <br>
</details>
<br>

<details>
    <summary><strong>Creative destruction</strong></summary>
    <br>

Outdated product replaced by new ones due to innovation. 

Creative destruction has plenty of examples: horse wagons, typewriters, newspapers, cassette tapes, compact disks, MP3 players and landlines replaced by modern technologies. Creative destruction refers to the product and process innovation mechanism by which new production units replace outdated ones. Creative destruction is most often used to describe disruptive technologies such as the railroads or Kodak cameras being replaced by mobile phones.  Creative destruction reminds us that things will change over time and the best way to avoid is to adapt. Creative destruction is a powerful economic concept because it can explain many of the dynamics or kinetics of economical change of an organization.

**History**: The term was coined in the early 1940s by economist Joseph Schumpeter, who observed real-life examples of creative destruction, such as Henry Ford’s assembly line. Schumpeter characterized creative destruction as innovations in the manufacturing process that increase productivity, describing it as the “process of industrial mutation that incessantly revolutionizes the economic structure from within, incessantly destroying the old one, incessantly creating a new one.” His theory assumed that long-standing arrangements and assumptions must be destroyed to free up resources and energy to be deployed for innovation. Marx never coined the term, however, he explicitly explained the concept in *The Communist Manifesto* of 1848:

> ... a society that has conjured up such gigantic means of production and of exchange, is like the sorcerer who is no longer able to control the powers of the nether world whom he has called up by his spells. ... It is enough to mention the commercial crises that by their periodical return put the existence of the whole of bourgeois society on trial, each time more threateningly. In these crises, a great not only of existing production, but also of previously created productive forces, are periodically destroyed.

> The productive forces at the disposal of society no longer tend to further the development of the conditions of bourgeois property; on the contrary, they have become too powerful for these conditions. ... And how does the bourgeoisie get over these crises? On the one hand by enforced destruction of a mass of productive forces; on the other, by the conquest of new markets, and by the more thorough exploitation of the old ones. That is to say, by paving the way for more extensive and more destructive crises, and by diminishing the means whereby crises are prevented.

Marx in his other writings:

> Again, however, from destruction a new spirit of creation arises; the scarcity of wood and the needs of everyday life... forced the discovery or invention of substitutes for wood, forced the use of coal for heating, forced the invention of coke for the production of iron.

Charles Darwin also had mentioned similar observations in *Origin of Species* of 1859:

> ...extinction of old forms is the almost inevitable consequence of the production of new forms.

**Clayton Christensen**: As a professor at Harvard Business School, Clayton Christensen pioneered in the late 1990s some principles and steps business managers should take to defend their franchises from newcomers.

1. *Creative destruction* placed on the backs of successful companies the duty that they work to “destroy” that which has made them historically rich and great. If they did not destroy their own franchise in search of a superior replacement, some young upstart enterprise in a garage somewhere (most likely Silicon Valley) would do it for them. 
2. *Innovator’s dilemma* suggested that companies with established dominance all too often do not innovate sufficiently, fearing that innovations would not deliver the type of profits delivered by standard and long tried-and-true businesses that made them great.

> The reason why it is so difficult for existing firms to capitalize on disruptive innovations is that their processes and their business model that make them good at the existing business actually make them bad at competing for the disruption.

To remain great you have to be willing to give up what you have and need for what you can only at best hope that you might retain.

**Markets always win**: When mental models are out of sync with reality, corporations lose their status by staying complacent. They don’t have much control over market. In the end, market always win! Markets lack culture, leadership and emotion which corporations face. The market has no memory or remorse. It has no mental models. The market forces are at constant play working themselves out. Market will always welcome new entrants and kill the old. So if market always win, then, what role can corporations play?

**Beginner’s mindset**: In Buddhism, the act of openness to trying new things and not carrying the burden of past assumptions is called beginner’s mind. It allows for new ideas and innovation to flourish. To avoid creative destruction, understand competition constantly dismantle the old guards. Having a beginner’s mindset is wise for corporate executives to embrace.

> Knowing you have a competitive advantage is often the enemy of beginner’s mind, because doing well reduces the incentive to explore other ideas, especially when those ideas conflict with your proven strategy. — Morgan Housel

Morgan Housel has a great piece worth reading, [why competitive advantages die](https://www.collaborativefund.com/blog/why-competitive-advantages-die/).

 <br>
</details>

## Business & Finance
| Model | Definition | 
| -------------|:-------------:|
| Pari-mutuel system | A system of betting where the bets are pooled and the winners share the money after the house, or organizer, has taken their cut. |
| _Risk vs uncertainty vs volatility_ | Risk is an unknown, but you can predict the probability of it. Uncertainty is an unknown and you cannot predict the probability of it. Volatility refers to short term change and does not mean that something is risky in the long term. Volatility represents how large prices can swing around the mean. |
| _Mr market_ | Mr. Market is a metaphor that represents moody behavior of stock market fluctuation. |
| _Economic moat_ | A competitive advantage a company has over its competitors to defend its long-term profitability. |
| _Diminishing returns_ | The value of each additional input leads to a decreasing level of output. At this stage the effort of productivity decreases. |
| _Circle of competence_ | Describes a person’s competency in an area that matches their skillset and abilities. |
| _Occam's razor_ | Occam’s razor states that the simplest explanation is preferable over a complex one. |

<details>
    <summary><strong>Pari-mutuel system</strong></summary>
    <br>

A system of betting where the bets are pooled and the winners share the money after the house, or organizer, has taken their cut.

The parimutuel system is used in gambling on horse racing, greyhound racing, and other sporting events of relatively short duration in which participants finish in a ranked order. A modified parimutuel system is also used in some lottery games. The odds are discovered at the end of the event, rather than being set at the beginning. In Pari-mutuel betting the gambler bets against other gamblers, not the house.

> …you don’t win by predicting the future; you win by getting the odds right. You can be right about the future and still not make any money. At the racetrack, for example, the favorite horse may be the one most likely to win, but since everyone wants to bet on the favorite, how likely is it that betting on the favorite will make you money? The horse to bet on is the one more likely to win than most people expect. That’s the one that gives you the best odds. That’s the bet that pays off over time. — Will Bonner

> The model I like to sort of simplify the notion of what goes o­n in a market for common stocks is the pari-mutuel system at the racetrack. If you stop to think about it, a pari-mutuel system is a market. Everybody goes there and bets and the odds change based o­n what’s bet. That’s what happens in the stock market. Any damn fool can see that a horse carrying a light weight with a wonderful win rate and a good post position etc., etc. is way more likely to win than a horse with a terrible record and extra weight and so o­n and so on. But if you look at the odds, the bad horse pays 100 to 1, whereas the good horse pays 3 to 2. Then it’s not clear which is statistically the best bet using the mathematics of Fermat and Pascal. The prices have changed in such a way that it’s very hard to beat the system.And then the track is taking 17% off the top. So not only do you have to outwit all the other betters, but you’ve got to outwit them by such a big margin that on average, you can afford to take 17% of your gross bets off the top and give it to the house before the rest of your money can be put to work. — Charlie Munger

 <br>
</details>
<br>

<details>
    <summary><strong>Risk vs uncertainty & volatility</strong></summary>
    <br>

Risk is an unknown, but you can predict the probability of it. Uncertainty is an unknown and you cannot predict the probability of it. Volatility refers to short-term change and does not mean that something is risky in the long term. In business & finance all 3 are critical component of decision-making process. Knowing the difference between these will help you make better decisions. 

- Risk is when the odds or probabilities of future events can be estimated.
- Uncertainty is when the list of possible future events is unknown, so their odds of occurring cannot be estimated. 
- Volatility represents how large prices can swing around the mean.

Uncertainties are open-ended with many possibilities. Risks and volatility have a narrow range of outcomes with odds that can be estimated. Risk is the situation under which the decision outcomes and their probabilities of occurrences are known to the decision-maker, and uncertainty is the situation under which such information is not available to the decision-maker.

- In risk, you can predict the possibility of a future outcome, while in uncertainty you cannot.
- Risks can be managed while uncertainty is uncontrollable.
- Risks can be measured and quantified, while uncertainty cannot.
- You can assign a probability to risks events, while with uncertainty, you can’t.

The 2020 coronavirus pandemic is an example of making decisions under uncertainty. When the pandemic first hit, you didn’t know the probabilities of getting sick, and if you fell ill, you didn’t know the odds of dying. You also didn’t know who was infected or even how we could get infected. The situation was highly uncertain. In those circumstances, the minimax regret decision was to shelter in place as much as possible until you had more information on fatality statistics. Minimizing our regret is not an optimization problem. It is a behavioral coping mechanism for dealing with uncertainty.

> Risk is what’s left when you think you’ve thought of everything. — Carl Richards

> What is risk? It is a probability of negative event in the future. What does past tell us about that? The past has relevance but it is not absolute. Risk cannot be quantified that is why I don’t believe in models. And what is quantification, it is a measurement. And future events cannot be measured. — Howard Marks

> There’s a big difference between probability and outcome. Probable things fail to happen—and improbable things happen—all the time. That’s one of the most important things you can know about investment risk. — Howard Marks

> Risk means uncertainty about which outcome will occur and about the possibility of loss when the unfavorable ones do. — Howard Marks

> Experience is what you get when you get something you don’t want. The best way to learn lessons is inexpensively. — Howard Marks

> You should obsess over risks that do permanent damage and care little about risks that do temporary harm, but the opposite is more common. The only way to build wealth is to have a gap between your ego and your income. It’s important to know the difference between rosy optimism and periods of chaos that trend upward. If your expectations grow faster than your income you’ll never be happy with your money no matter how much you accumulate. — Morgan Housel

> There are known knowns. These are things we know that we know. There are known unknowns. That is to say, there are things that we know we don’t know. But there are also unknown unknowns. These are things we don’t know we don’t know. — Former U.S. secretary of defense Donald Rumsfeld

> Risk has an unknown outcome, but we know what the underlying outcome distribution looks like. Uncertainty also implies an unknown outcome, but we don’t know what the underlying distribution looks like. So games of chance like roulette or blackjack are risky, while the outcome of a war is uncertain. Knight said that objective probability is the basis for risk, while subjective probability underlies uncertainty. — Michael Mauboussin 

> Risk, as first articulated by the economist Frank H. Knight in 1921, is something that you can put a price on. Say that you’ll win a poker hand unless your opponent draws to an inside straight: the chances of that happening are exactly 1 chance in 11. This is risk. It is not pleasant when you take a “bad beat” in poker, but at least you know the odds of it and can account for it ahead of time. In the long run, you’ll make a profit from your opponents making desperate draws with insufficient odds. Uncertainty, on the other hand, is risk that is hard to measure. You might have some vague awareness of the demons lurking out there. You might even be acutely concerned about them. But you have no real idea how many of them there are or when they might strike. Your back-of-the-envelope estimate might be off by a factor of 100 or by a factor of 1,000; there is no good way to know. This is uncertainty. Risk greases the wheels of a free-market economy; uncertainty grinds them to a halt. — Nate Silver

> The meaning of “uncertainty” and “risk” and the distinction between them seems ambiguous even for some experts in the field and there are multiple definitions of each in use… Indeed, the decision sciences routinely write about “decisions under uncertainty” where uncertainty is defined with quantified probabilities. Physicists routinely talk about measuring uncertainty—again with probabilities. — Douglas Hubbard 

> With uncertainties, you don’t know the probabilities, so you do your best to avoid situations where you could be ruined and experience tremendous regret. “The concept of regret is a much more powerful and flexible concept than mere loss because it is entirely subjective. But that’s exactly what makes the strategy human. That’s exactly what makes the strategy real. — Ben Hunt

> In the face of uncertainty we cope as humans, we don’t optimize. — Mervyn King, former Bank of England Chair

> Volatility in the up direction is not a problem-it's only downward volatility that offers discourse. — Coreen T. Sol

 <br>
</details>
<br>

<details>
    <summary><strong>Mr market</strong></summary>
    <br>

Mr. Market is a metaphor that represents moody behavior of stock market fluctuation.

The mood fluctuates depending on what mood the Mr. Market is in. If the general sentiment is negative, Mr. Market delivers low stock prices. If the sentiment is positive, Mr. Market tends to offer high stock prices. Mr. Market is a mental model on how to view the market behavior. Mr. Market is a fictional character who is driven by many emotions and mood on any given day rather than through rational analysis. Mr. Market should only be taken seriously when prices presented are favorable to you. 

Mr. Market is a fictional character created by investor and professor Benjamin Graham to describe irrational behavior of stock market. He explained Mr. Market as a daily visitor knocking on your door offering stock prices that you can buy or sell at. You can either transact with Mr. Market or ignore him.  Graham introduced Mr. Market in Chapter 8 of his classic book *The Intelligent Investor*. Graham explained the unstable character of Mr. Market who wakes up happy one day, and sad the other day. He further explains the job of an investor is to take advantage of him on the days when he is in bad mood offering depressed prices.

> In the short run, the market is a voting machine but in the long run, it is a weighing machine. — Benjamin Graham

Benjamin Graham was also Warren Buffett's intellectual father.

> If you understand chapters 8 and 20 of The Intelligent Investor (Benjamin Graham, 1949) and chapter 12 of the General Theory (John Maynard Keynes, 1936), you don’t need to read anything else and you can turn off your TV. — Warren Buffett

Imagine if you own a local grocery store and if Mr. Market showed up everyday with different prices on what your business is worth. You would most likely ignore him and focus on serving your customers. You will have a better idea on how your business is performing based on your financial reports. But Mr. Market does not care about your insights! Mr. Market is that annoying neighbor who does not care if you are interested. He will show up everyday whether you like him or not. The wisdom to ignore Mr. Market is hard to put in practice because it requires a lot of patience. Benjamin Graham wrote the following passage in Chapter 7 of The Intelligent Investor:

> The true investor scarcely ever is forced to sell his shares, and at all other times he is free to disregard the current price quotation. He need pay attention to it and act upon it only to the extent that it suits his book, and no more. Thus the investor who permits himself to be stampeded or unduly worried by unjustified market declines in his holdings is perversely transforming his basic advantage into a basic disadvantage. That man would be better off if his stocks had no market quotation at all, for he would then be spared the mental anguish caused him by other persons’ mistakes of judgment.

Jason Zweig is a Wall Street Journal columnist who has been revising *The Intelligent Investor* to keep up with times has commented on the passage above:

> This may well be the single most important paragraph in Benjamin Graham’s entire book. In these 113 words Graham sums up his lifetime of experience. You cannot read these words too often; they are like Kryptonite for bear markets. If you keep them close at hand and let them guide you throughout your investing life, you will survive whatever the markets throw at you.

Warren Buffett explains further on Mr. Market in his 1987 Berkshire Hathaway shareholder letter:

> Ben Graham, my friend and teacher, long ago described the mental attitude toward market fluctuations that I believe to be most conducive to investment success. He said that you should imagine market quotations as coming from a remarkably accommodating fellow named Mr. Market who is your partner in a private business. Without fail, Mr. Market appears daily and names a price at which he will either buy your interest or sell you his. Even though the business that the two of you own may have economic characteristics that are stable, Mr. Market’s quotations will be anything but. For, sad to say, the poor fellow has incurable emotional problems. At times he feels euphoric and can see only the favorable factors affecting the business. When in that mood, he names a very high buy-sell price because he fears that you will snap up his interest and rob him of imminent gains. At other times he is depressed and can see nothing but trouble ahead for both the business and the world. On these occasions he will name a very low price, since he is terrified that you will unload your interest on him. Mr. Market has another endearing characteristic: He doesn’t mind being ignored. If his quotation is uninteresting to you today, he will be back with a new one tomorrow. Transactions are strictly at your option. Under these conditions, the more manic-depressive his behavior, the better for you. But, like Cinderella at the ball, you must heed one warning or everything will turn into pumpkins and mice: Mr. Market is there to serve you, not to guide you. It is his pocketbook, not his wisdom, that you will find useful. If he shows up some day in a particularly foolish mood, you are free to ignore him or to take advantage of him, but it will be disastrous if you fall under his influence. Indeed, if you aren’t certain that you understand and can value your business far better than Mr. Market, you don’t belong in the game. As they say in poker, “If you’ve been in the game 30 minutes and you don’t know who the patsy is, you’re the patsy...In my own efforts to stay insulated, I have found it highly useful to keep Ben’s Mr. Market concept firmly in mind.

Charlie Munger on Mr. Market:

> Of course, the best of [Benjamin Graham's approach] was his concept of "Mr. Market". Instead of thinking the market was efficient, Graham treated it as a manic-depressive who comes by every day. And some days "Mr. Market" says, "I'll sell you some of my interest for way less than you think is worth." And other days, he comes by and says "I'll buy your interest at a price that's way higher than what you think it's worth." And you get the option of deciding whether you want to buy more, sell of what you already have, or do nothing at all. To Graham, it was a blessing to be in a business with a manic-depressive who gave you this series of options all the time. That was a very significant mental construct. And it's been very useful to Buffett, for instance, over his whole adult lifetime.

Seth Klarman, another legendary investor on Mr. Market:

> An ever helpful fellow, Mr. Market stands ready every business day to buy or sell a vast array of securities in virtually limitless quantities at prices that he sets. He provides this valuable service free of charge. Sometimes Mr. Market sets prices at levels where you would neither want to buy nor sell. Frequently, however, he becomes irrational. Sometimes he is optimistic and will pay far more than securities are worth. Other times he is pessimistic, offering to sell securities for considerably less than underlying value. Value investors – who buy at a discount from underlying value – are in a position to take advantage of Mr. Market’s irrationality. Some investors – really speculators – mistakenly look to Mr. Market for investment guidance. They observe him setting a lower price for a security and, unmindful of his irrationality, rush to sell their holdings, ignoring their own assessment of underlying value. Other times they see him raising prices and, trusting his lead, buy in at the higher figure as if he knew more than they. The reality is that Mr. Market knows nothing, being the product of the collective action of thousands of buyers and sellers who themselves are not always motivated by investment fundamentals. Emotional investors and speculators inevitably lose money; investors who take advantage of Mr. Market’s periodic irrationality, by contrast, have a good chance of enjoying long-term success. Mr. Market’s daily fluctuations may seem to provide feedback for investors’ recent decisions. For a recent purchase decision rising prices provide positive reinforcement; falling prices, negative reinforcement. If you buy a stock that subsequently rises in price, it is easy to allow the positive feedback provided by Mr. Market to influence your judgment. You may start to believe that the security is worth more than you previously thought and refrain from selling, effectively placing the judgment of Mr. Market above your own. You may even decide to buy more shares of this stock, anticipating Mr. Market’s future movements. As long as the price appears to be rising, you may choose to hold, perhaps even ignoring deteriorating business fundamentals or a diminution in underlying value. Similarly, when the price of a stock declines after its initial purchase, most investors, somewhat naturally, become concerned. They start to worry that Mr. Market may know more than they do or that their original assessment was in error. It is easy to panic and sell at just the wrong time. Yet if the security were truly a bargain when it was purchased, the rational course of action would be to take advantage of this even better bargain and buy more. The fact that a stock price rises does not ensure that the underlying business is doing well or that the price increase is justified by a corresponding increase in underlying value. Likewise, a price fall in and of itself does not necessarily reflect adverse business developments or value deterioration. It is vitally important for investors to distinguish stock price fluctuations from underlying business reality. If the general tendency is for buying to beget more buying and selling to precipitate more selling, investors must fight the tendency to capitulate to market forces. You cannot ignore the market – ignoring a source of investment opportunities would obviously be a mistake – but you must think for yourself and not allow the market to direct you. Value in relation to price, not price alone, must determine your investment decisions.

To deal with Mr. Market, you need a right temperament and virtues because market is unpredictable but your behavior is not. Great investment returns lie in doing nothing, but we all deal with do-something-syndrome. Let Mr. Market serve you, not guide you! Take advantage of prices when they are attractive to you!

 <br>
</details>
<br>

<details>
    <summary><strong>Economic moat</strong></summary>
    <br>

A competitive advantage a company has over its competitors to defend its long-term profitability.

A company has a moat when it has a valuable network effect. Twitter has a network effect because its members enjoy the benefit of connecting with more people. As Twitter network grows larger, there is more incentive for people to join.

Or...

Imagine the process of switching banks and updating all of your billing accounts. It is inconvenient for customers because they have to bear the switching costs. Higher switching costs provide banks an economic moat. The ability of a business to protect itself and create long-term competitive advantages. Companies such as Walmart can undercut competitors and negotiate supplier discounts due to a high volume of sales. There are several factors that define an economic moat — pricing power (Apple), intangible assets (Disney — branding, customer loyalty and patents), cost advantages (Walmart), switching costs (Chase bank), network effects (Facebook), and efficient scale (Amazon) are all advantages a business can leverage on to build or protect its moat.

> How do you compete against a true fanatic? You can only try to build the best possible moat and continuously attempt to widen it. — Charlie Munger

> Unless a company has an economic moat protecting its business, competition will soon arrive on its doorstep and eat away at its profits. Wall Street is littered with the dead husks of companies that went from hero to zero in a heartbeat. — Pat Dorsey

> Our criterion of “enduring” causes us to rule out companies in industries prone to rapid and continuous change. Though capitalism’s “creative destruction” is highly beneficial for society, it precludes investment certainty. A moat that must be continuously rebuilt will eventually be no moat at all. — Warren Buffett

> In business, I look for economic castles protected by unbreachable 'moats'. — Warren Buffett

> No formula in finance tells you that the moat is 28 feet wide and 16 feet deep. That's what drives the academics crazy. They can compute standard deviations and betas, but they can't understand moats. — Warren Buffett

Warren Buffett, one of the greatest investors of our time conceptualized the term. The illustration of moats is derived from water-filled moats that surrounded medieval castles. Water acted as a moat to protect kingdoms and castles from invaders. The wider the moat, the more difficult it would be for an invader to reach the castle. The narrower or no moat, allowed the invader to reach the castle. Water alone didn't play a key role in protecting moats. Army, weapons and strategic ruler also played a role in defining and protecting kingdom's moat.

Business moat is analogous to kingdom's moat. Understanding economic moat is crucial to survival for any business. It describes a company's ability to earn above-average profits for a long period of time. No moat businesses often face threats from invaders, also known as competitors. Rapid innovation in technology has prevented businesses to protect its moat. Wide moat businesses benefit from one or several factors but they are also able to generate above-average profits for a long period of time. This profit can either be reinvested back into a business (Amazon) or return excess cash back to investors (Apple).

Wide moat businesses require competent management with excellent capital allocation skills. For every decision being made there is an opportunity cost. Reinvesting excess cash can be risky and investors would have to hold off for a payout. But great capital allocators see opportunities where others don't, turning a company into a size of many folds. Jeff Bezos of Amazon is a great example of an efficient capital allocator. Let's take a look at some of the main factors that drives economic moat.

- _Technology_: deep technology such as artificial intelligence (AI) and data warehouse can give company an edge. Patents and trademarks make it hard to copy proprietary technology such as Google's search engine.
- _Economies of scale_: The bigger the better because it brings down the cost and creates operating leverage. Economies of scale give cost advantage to businesses. Software companies do this efficiently because it costs minimal to nothing for each additional customer.
- _Network effects_: The value of of a platform is proportional to the number of people using the platform. More people leads to more content and more time spent. Social media platforms such as Facebook or Snapchat are classic examples.
- _Intangible assets_: Patents, brands, regulatory licenses can prevent competitors from duplicating a company's product. This in turn allows a company to charge premium for its products. A strong brand breeds trust. Apple is a classic example for all of its intangible assets.
- _Switching costs_: If a customer has a high switching cost, it is very unlikely customers will take their business somewhere else. Switching costs can be due to cost or time intensive. Bank customers have high switching costs.

Technology has made switching costs easy for customers due to better product integration. It is easy for customers to download their old data and import it on a new software. Be careful how these factors are evolving with rapid technology innovation. Old economic moats are still sound but are evolving with time. Walmart is a wide moat business but Amazon was able to eat its lunch by bringing unlimited shelf space using web technologies. Strong moats survive major platform or trend shifts, but surviving should not be confused with thriving. IBM has survived major technological shifts, but is struggling to thrive. It is a victim of its own success because it failed to recognize industry-wide transformations. The major key takeaway of economic moat — is the end state defensible? If not, why go there?

 <br>
</details>
<br>

<details>
    <summary><strong>Diminishing returns</strong></summary>
    <br>

The value of each additional input leads to a decreasing level of output. At this stage the effort of productivity decreases.

Doing too much of something may lead to diminishing or negative returns. For example, exercising to a level of exhaustion without giving your body a rest is counterproductive. Another example is giving money to poor family which will help them escape poverty. However, after a certain threshold additional dollar won’t have much impact. Receiving too much money could destroy the poor family.

Law of diminishing returns, also referred to as the law of diminishing marginal returns, is a concept in economics that if one factor of production (e.g. number of workers) is increased while other factors (e.g. work area or equipment) are held constant, the output per unit of the variable factor will eventually diminish. In other words, keeping all other factors constant, the additional output gained by another one unit increase of the input variable will eventually be smaller than the additional output gained by the previous increase in input variable. That is the point at which the diminishing marginal returns take effect.

A common example of diminishing returns is choosing to hire more to increase productivity. A farmer who owns a 25 acres hires 5 workers to harvest the field. Farmer will benefit tremendously per hire. But hiring 5 more will not yield the same level of productivity. This is because not every unit of input will lead to a proportional increase of output. The marginal productivity of the workforce decreases as output increases. Therefore, the total output per hire would be less. The law of diminishing returns states that simply increasing one input while keeping others the same will at some point yield diminishing returns. Basically, the extra output obtained by increasing one input, while the other inputs are constant, decreases over time.

> Assuming you are effectively iterating the product based on customer feedback and research, you will eventually hit a point where there’s just not that much you can do to make it better. It’s time for your team to move on and invest in something new. — Brandon Chu

**Income and happiness**: Diminishing returns refers to any situation where your marginal benefits (income, happiness) is decreasing as the number of resources (time, inputs) increases. The extra boost of happiness you get from eating out 15th time should be less than the happiness you got from the 10th time.

**Negative returns**: The law of diminishing return does not state that adding more input will decrease the total production. It rather suggests the margins will continue to decrease eventually leading into negative territory.

 <br>
</details>
<br>

<details>
    <summary><strong>Circle of competence</strong></summary>
    <br>

Describes a person’s competency in an area that matches their skillset and abilities.

Once upon a time Michael Jordan tried playing baseball, but he couldn't perform at the same caliber as basketball. Michael Jordan's circle of competency was basketball, not baseball. The circle of competency describes the skills and abilities of a person. These competencies can be innate or acquired through experiences over time. An understanding and knowing the boundaries of one's competencies are vital in avoiding downfalls and stress.

Ted Williams was famously known to wait for the “fat pitch.” He would only swing at pitches in of the strike zone where he knew he had a higher probability of getting a hit. There were parts of his strike zone where he batted .230 and there were other parts of the strike zone where he batted .400. He patiently waited to swing at pitches that would improve his odds of getting a hit and increase his overall batting average. Ted Williams operated within his circle of competency. So did Andrew Carnegie. Carnegie was a business icon during his era. In the *Autobiography of Andrew Carnegie*, Carnegie gives the following advice:

> I believe the true road to preeminent success in any line is to make yourself master in that line. I have no faith in the policy of scattering one’s resources, and in my experience I have rarely if ever met a man who achieved preeminence in money-making—certainly never one in manufacturing—who was interested in many concerns. The men who have succeeded are men who have chosen one line and stuck to it.

Warren Buffett wrote a letter to Berkshire Hathaway shareholders in 1996 that shows what it means to operate within a circle of competency:

> What an investor needs is the ability to correctly evaluate selected businesses. Note that word “selected”: You don’t have to be an expert on every company, or even many. You only have to be able to evaluate companies within your circle of competence. The size of that circle is not very important; knowing its boundaries, however, is vital.

So let's imagine a few circles! The imaginary circle of competence lies as a small circle within a much larger circle. The larger circle represents what an individual *thinks* they know but are far from being an expert in. Conversely, the smaller circle represents what they *actually* know and could be considered an expert in. To be successful, widening the competency circle is much more valuable than jumping from one circle to another.

Stick to what you know and know your limitations. Even the most famous icons were self-aware of that.

> I’m no genius. I’m smart in spots—but I stay around those spots. — Tom Watson Sr., Founder of IBM

> I consider that a man’s brain originally is like a little empty attic, and you have to stock it with such furniture as you choose. — Sherlock Holmes

> The first thing to notice about specific knowledge is that you can’t be trained for it… [it’s] found much more by pursuing your innate talents, your genuine curiosity, and your passion… [it’s’] the knowledge that you care about. Especially if you’re later in life, let’s say your post 20, 21, 22, you almost don’t get to choose which specific knowledge you have. Rather, you get to look at what you have already built by that point in time, and then you can build on top of it. — Naval Ravikant

Your circle of competence is the subject area that matches your skills and expertise. But, many of us feel that our circle of competency is bigger than it actually is. Overconfidence starts leading us in a wrong direction. Reading a few set of books does not make someone a doctor or a lawyer. Those expertise come from decade of studies and practical experiences. It cannot be developed overnight by quickly jumping from one circle to another.

To improve the odds of success in life and business, the perimeter of your circle of competency needs to be defined so you can operate within the circle. Over time, the circle expands depending on your hard work and luck, but never fool yourself that you can be a master of all circles.

**What is inside a circle of competency?**: It is shaped by many things. First, we are naturally good at something because of our innate abilities. For example, a two year old might be really good at playing a piano. Second, as we get older, we accumulate skills and expertise based on our experiences. For example, learning a piano at an early age can help one become an expert. Core competencies can be innate, acquired or both.

**How wide is a circle of competency?**: Knowing where the boundaries of a circle of competency are and where you stand within those boundaries is really important. Understanding your own circle of competency helps you concentrate on the areas where you have the greatest familiarity.

> Everybody’s got a different circle of competence. The important thing is not how big the circle is. The important thing is staying inside the circle. — Warren Buffett

Being truthful about your competencies can eliminate any illusions. There are times when subjective assessment of your own competence with your actual competence are misaligned. This is how people get in trouble. They stray from the circle of "what you know" into the circle of "what you don't know." Charlie Munger took the concept one step further by playing the strengths to have a competitive advantage. If a person not playing to their strengths comes up against a person who is, they will most likely lose. Charlie Munger on the boundaries of circle of competency:

> If you have competence, you pretty much know its boundaries already. To ask the question (of whether you are past the boundary) is to answer it.

> You have to figure out what your own aptitudes are. If you play games where other people have the aptitudes and you don’t, you’re going to lose. And that’s as close to certain as any prediction that you can make. You have to figure out where you’ve got an edge. And you’ve got to play within your own circle of competence. If you want to be the best tennis player in the world, you may start out trying and soon find out that it’s hopeless—that other people blow right by you. However, if you want to become the best plumbing contractor in Bemidji, that is probably doable by two-thirds of you. It takes a will. It takes the intelligence. But after a while, you’d gradually know all about the plumbing business in Bemidji and master the art. That is an attainable objective, given enough discipline. And people who could never win a chess tournament or stand in center court in a respectable tennis tournament can rise quite high in life by slowly developing a circle of competence—which results partly from what they were born with and partly from what they slowly develop through work.

**How to widen a circle of competency?**: Widening your circle of competencies can be done in many ways. Ask questions. Learn. Read. Work for someone who you can accumulate experiences from. Learn by doing. If something falls outside of your competency, delegate or outsource.

As Charlie Munger says:

> In my whole life, I have known no wise people (over a broad subject area) who didn’t read all the time – none, zero. You’d be amazed at how much Warren Buffett reads – and how much I read. My children laugh at me. They think I’m a book with a couple of legs sticking out.

There is a difference between *real knowledge* and *surface knowledge*. Richard Feynman distinguished *knowing the name of something* vs *knowing something*. Real knowledge comes from doing deep work, experimenting and experiencing. Pretending to know outside of your circle can have real consequences. It serves well when you can say, “I don't know.” Confidence and humility are equally important.

**Why should you avoid jumping from one circle to another?**: It is natural to step outside and explore outside of our core circles. We have been doing this ever since the humanity started. However, attempting to broaden the circles should be done deliberately. Skills from one industry to another are not easily transferable. For example, an engineer cannot wake up tomorrow and start conducting surgeries. Not all stories turned out to be successful amongst the most successful icons we know today.

- Peter Thiel went from being a venture capitalist to becoming a macro trader.
- Famous economists who won the Nobel prize launched LTCM to taking enormous amount of leverage.
- Fund manager such as George Soros trading technology stocks.

Charlie Munger on avoiding things he does not understand:

> Why should I buy something that I don't understand?

> I think about things where I have an advantage over other people. I don’t play in a game where the other people are wise and I’m stupid. I look for a place where I’m wise and they’re stupid. You have to know the edge of your own competency. I’m very good at knowing when I can’t handle something.

This is not to say DO NOT jump outside of your circle. Should you expand your skills? Yes, of course! But slowly...

It takes a very long time to build meaningful skills. If you are deliberate about committing to learning something new for a long period of time, it will be a worthwhile exercise to cross over the edges of your core competencies. But don't catapult yourself a hundred miles outside of your circle. You will fall flat on your face. To be a life-longer is a competitive advantage. Not everyone is born with natural talents, but skills can be acquired over time.

 <br>
</details>
<br>

<details>
    <summary><strong>Occams razor</strong></summary>
    <br>

Occam’s razor states that the simplest explanation is preferable over a complex one. 

Philosophers select explanations with the fewest assumptions when faced among competing hypotheses. Occam’s razor is named after the 14th-century English logician and theologian, William of Ockham. This philosophical razor advocates that when presented with competing hypotheses about the same prediction, one should select the solution with the fewest assumptions, and that this is not meant to be a way of choosing between hypotheses that make different predictions. All things being equal, the simplest solution tends to be the best. We should discard the things which are unknowable and unimportant. Just because something is complicated, it does not mean it is worth anything. Keep everything simple. Albert Einstein had a preference for simplicity which shows in his famous equation E=MC2. He once said:

> Everything should be made as simple as possible, but not simpler.

He could’ve settled for a complex and lengthy equation, but instead he settled for simplicity. 

Stephen Hawking also advocated for Occam’s razor:

> We could still imagine that there is a set of laws that determines events completely for some supernatural being, who could observe the present state of the universe without disturbing it. However, such models of the universe are not of much interest to us mortals. It seems better to employ the principle known as Occam’s razor and cut out all the features of the theory that cannot be observed.

Simplification is a powerful weapon in complex environments. There is a lesson in this beyond scientific theories. 

**Engineering**: In engineering, it’s the KISS principle: keep it simple, stupid. It employs avoiding complexity and over specification.

**Writing**: Given two written passages which convey almost the same meaning, the shorter passage is usually better. Shortening makes writing clearer and more vivid. 

**Productivity**: **Have you ever wondered why billionaires like Mark Zuckerberg or Steve Jobs always wear the same clothes? To avoid decisions. Having to wake up every day with a toll of what to wear is not good use of their time. This technique is employed beyond the billionaires club. Anyone who seeks to be productive simplify their daily cognitive load.

**Investing**: Simplicity is the way to long term success in investing. Warren Buffett on simplification in investing:

> The business schools reward difficult complex behavior more than simple behavior, but simple behavior is more effective….We haven’t succeeded because we have some great, complicated systems or magic formulas we apply or anything of the sort. What we have is just simplicity itself.

> After 25 years of buying and supervising a great variety of businesses, Charlie and I have not learned how to solve difficult business problems. What we have learned is to avoid them. To the extent we have been successful, it is because we concentrated on identifying one-foot hurdles that we could step over rather than because we acquired any ability to clear seven-footers. The finding may seem unfair, but in both business and investments it is usually far more profitable to simply stick with the easy and obvious than it is to resolve the difficult.

> …we try to stick to businesses we believe we understand. That means they must be relatively simple and stable in character. If a business is complex or subject to constant change, we’re not smart enough to predict future cash flows. Incidentally, that shortcoming doesn’t bother us.

Charlie Munger who is Buffett’s business partner also agrees:

> People calculate too much and think too little….we have a passion for keeping things simple. If something is too hard, we move on to something else. What could be more simple than that?

Instead of worrying about where the interest rates or economic headwinds or tails winds are going, focus on what is knowable. Avoiding unknowable is an act of simplification. Buffett explains:

> There are two questions you ask yourself as you look at the decision you’ll make. A) is it knowable? B) is it important? If it is not knowable, as you know there are all kinds of things that are important but not knowable, we forget about those. And if it’s unimportant, whether it’s knowable or not it won’t make any difference. We don’t care.

Even the world’s best behavioral economist, Professor Daniel Kahneman suggests that we should simplify our financial plan:

> Keep it simple and aim to beat inflation. Don’t try to beat the market. When it comes to investing, less is more. And if you try to do more, you’ll often end up with less.

Make fewer decisions to make better decisions.

**Use caution**: While Occam’s razor is a popular mental model, bear in mind that Occam’s Razor doesn’t prove anything. It does not mean the world is simpler. Einstein proves the point: 

> For every complex problem there is an answer that is clear, simple, and wrong. — H. L. Mencken

> In my opinion the theory here is the logically simplest relativistic field theory that is at all possible. But this does not mean that Nature might not obey a more complex theory.

Occam’s razor is not an alternative for critical and logical thinking. It only states that simpler solutions are easier to understand and teach over the complex ones. Opting for simpler solutions still requires work. Simplifying is hard work and requires a lot of effort.

 <br>
</details>

## Psychology
| Model | Definition | 
| -------------|:-------------:|
|_Survivorship bias_| Our tendency to focus on successful examples and ignore failures. |
|_Man with a hammer syndrome_| To the man with a hammer, every problem looks like a nail. |
|_Twaddle tendency_| Twaddling means talking about something you don’t know, or just making up stuff as you go, or talking about meaningless stuff. |
|_Contrast mis-reaction tendency_| We don’t measure the value of things in a vacuum. We often notice value by contrasting it with something else. |
|_First conclusion bias_| A first principle is a basic assumption that cannot be deduced from any other assumption. |
|_Ideological bias_| Implicit values and assumptions embedded within texts, discourse, or social practices. |
|_Deprival super-reaction syndrome_| People are more affected by loss than by gains, or by what they have to lose. |
| _Lollapalooza effect_ | Munger's term for the phenomenon wherein different biases layer and interlock with one another. |
| _Social proof_| The kind of conformity to socially accept behavior is known as social proof. |
| _Liking disliking bias_ | We tend to dislike people who dislike us and tend to judge in favor of people that we know rather than strangers. |
| _Confirmation bias_ | The tendency of the human brain to filter out information that contradicts its existing beliefs. |
| _Reciprocation_ | Act of doing something nice for someone with the expectation that the favor will be returned. |
| _Reason respecting tendency_ | Ask questions to gain better understanding of the world. Failure to reason discourages first principles thinking. |
| _Kantian fairness tendency_ | The pursuit of absolute fairness for everyone and everything, but fairness differs from person to person. |

<details>
    <summary><strong>Survivorship bias</strong></summary>
    <br>

Our tendency to focus on successful examples and ignore failures. 

We tend to focus on the survivors and the winners for our information and discount the losers. If there are many successful bars in your area you may think about opening one yourself, but the bars which failed are invisible to you, their information is lost. This can lead to false conclusions in several different ways. It is a form of selection bias.

One classic example is the coverage of the success stories such as Bill Gates dropping out of Harvard then becoming a billionaire (or Mark Zuckerberg). This is contrasted by probably near zero mentions of the college dropouts who aren't billionaires.

Don’t listen to what you hear around you. Consider all the things that started on the same path but didn’t make it. 

<br>
</details>
<br>

<details>
    <summary><strong>Man with a hammer syndrome</strong></summary>
    <br>

To the man with a hammer, every problem looks like a nail.

You think of an idea and then, pretty soon, it becomes THE idea. You start seeing how THE idea can apply to anything and everything, it’s the universal explanation for how the universe works.

This essentially means that people are biased to use the tools they possess to solve problems, regardless of whether such tools are appropriate for the problem at hand. For most analysts working in finance, the “hammer” is forecasting and the “nail” is uncertainty. These analysts try to make precise forecasts about macroeconomic trends or a company’s earnings and give buy or sell ratings based on this.

If the only tool you have is a hammer, then every problem looks like a nail. If you have limited skills, you begin to see your skill set as the solution to every problem. It is better to have a wide variety of skills and approaches to solve problems with.

Munger on man with a hammer syndrome:

> I think I've got eight, no nine objections, some being logical subdivisions of a big general objection. The big general objection to economics was the one early described by Alfred North Whitehead when he spoke of the fatal unconnectedness of academic disciplines, wherein each professor didn't even know the models of the other disciplines, much less try to synthesize those disciplines with his own. I think there's a modern name for this approach that Whitehead didn't like, and that name is bonkers. This is a perfectly crazy way to behave. Yet economics, like much else in academia, is too insular....The nature of this failure is that it creates what I always call, 'man with a hammer syndrome.' And that's taken from the folk saying: To the man with only a hammer, every problem looks pretty much like a nail. And that works marvelously to gum up all professions, and all departments of academia, and indeed most practical life. The only antidote for being an absolute -5- klutz due to the presence of a man with a hammer syndrome is to have a full kit of tools. You don't have just a hammer. You've got all the tools. And you've got to have one more trick. You've got to use those tools checklist-style, because you'll miss a lot if you just hope that the right tool is going to pop up unaided whenever you need it. But if you've got a full list of tools, and go through them in your mind, checklist-style, you will find a lot of answers that you won't find any other way. So limiting this big general objection that so disturbed Alfred North Whitehead is very important, and there are mental tricks that help do the job. — Munger

<br>
</details>
<br>

<details>
    <summary><strong>Twaddle tendency</strong></summary>
    <br>

Twaddling means talking about something you don’t know, or just making up stuff as you go, or talking about meaningless stuff.

Some people like to work, others like to twaddle.

Many people try to hide their inadequacies by saying something when they have nothing to say. Big words, pompous language, and jargon are used to mask a lack of knowledge. We would rather ramble than to not know about a subject.

Be very careful of people who show false expertise.

> The principal job of an academic administration is to keep the people who don’t matter from interfering with the work of the people that do. — Munger

<br>
</details>
<br>

<details>
    <summary><strong>Contrast mis-reaction tendency</strong></summary>
    <br>

We don’t measure the value of things in a vacuum. We often notice value by contrasting it with something else. 

We often compare people and objects to other people and objects, evaluating their worth based on comparisons. We should evaluate these things individually, and not by their contrast to something else.

Our eyes evolved to identify and react to movement; to find the contrast in a static background. And so our brains followed. We are hypersensitive to contrast, while generally ignoring absolute values.

Our conscious mind is limited. Therefore, we can’t register every detail that we see, hear, feel, taste, and smell in every moment. Our brain unconsciously makes choices about where our attention flows. One of the ways that it makes this decision is by sudden change. Retailers take advantage of this by attaching an artificially high price to their product and then providing a significant discount. This is why you see many high-priced items on “sale” at the grocery store, the store marks them up ridiculously high, and then puts the product on “sale” for the standard price.  

Focus on absolute values, not the contrast between values.

<br>
</details>
<br>

<details>
    <summary><strong>First conclusion bias</strong></summary>
    <br>

First conclusion bias (also called confirmation bias) is a cognitive bias where early evidence produces a hard and fast conclusion. 

Our brains automatically seek evidence to confirm the first conclusion that we come to. This could be a way for our brains to conserve energy, but it can lead us to confirm a wrong conclusion in some situations.

As humans, we have developed this rapid thinking and reacting skills. The first conclusion is heavily influenced by personal biases and beliefs and is further complicated by attitude polarization. 

As Charlie Munger famously pointed out, the mind works a bit like a sperm and egg: the first idea gets in and then the mind shuts. Like many other tendencies, this is probably an energy-saving device. Our tendency to settle on first conclusions leads us to accept many erroneous results and cease asking questions; it can be countered with some simple and useful mental routines.

<br>
</details>
<br>

<details>
    <summary><strong>Ideological bias</strong></summary>
    <br>

Implicit values and assumptions embedded within texts, discourse, or social practices

A bias which is rooted in religious, political, or philosophical ideas. These ideologies can cloud judgment, leading us to search for evidence to back up our ideas and dismiss those which do not conform. Once the idea is rooted it is hard to get away from.

In psychology, cognitive dissonance is the discomfort experienced when simultaneously holding two or more conflicting cognitions: ideas, beliefs, values or emotional reactions.

> Another thing to avoid is extremely intense ideology because it cabbages up one’s mind. You see a lot of it in the worst of the TV preachers. They have different, intense, inconsistent ideas about technical theology, and a lot of them have minds reduced to cabbage. And that can happen with political ideology. And if you’re young, it’s particularly easy to drift into intense and foolish political ideology and never get out. When you announce that you’re a loyal member of some cult-like group and you start shouting out the orthodox ideology, what you’re doing is pounding it in, pounding it in. You’re ruining your mind, sometimes with starling speed. So you want to be careful with intense ideology. It presents a big danger for the only mind you’re ever going to have. — Munger

> I have what I call in “iron prescription” that helps me keep sane when I drift toward preferring one intense ideology over another. I feel that I’m not entitled to have an opinion unless I can state the arguments against my position better than the people who are in opposition. I think that I am qualified to speak only when I’ve reached that state. — Munger

> The business of not drifting into extreme ideology is very, very important in life. If you want to end up wise, heavy ideology is very likely to prevent that outcome. — Munger

 <br>
</details>
<br>

<details>
    <summary><strong>Deprival super-reaction syndrome</strong></summary>
    <br>

People are more affected by loss than by gains, or by what they have to lose.

Charlie Munger on a common psychological misjudgment that causes terrible problems—bias from deprival super-reaction syndrome. It is caused by present or threatened scarcity, including threatened removal of something almost possessed but never possessed.

It is a loss aversion. Loss aversion refers to people’s tendency to strongly prefer avoiding losses to acquiring gains. Most studies suggest that losses are twice as powerful, psychologically, as gains.

If something is taken away from a person or if that threat is present, even if they have only had it for a short time (or even no time at all), they will become irrationally upset.

> The Mungers once owned a tame and good-natured dog that displayed the canine version of Deprival Super Reaction Syndrome tendency. There was only one way to get bitten by the dog. And that was to try and take some food away from him after he already had it in his mouth. – Munger

 <br>
</details>
<br>

<details>
    <summary><strong>Lollapalooza effect</strong></summary>
    <br>

Munger's term for the phenomenon wherein different biases layer and interlock with one another.

In a 1995 speech at Harvard University titled _The Psychology of Human Misjudgement,_ Munger used open outcry auctions as an example of the Lollapalooza effect. Participants are pushed to bid by reciprocity (I should buy because I was invited to the auction), consistency (I have been on record saying that I like this so I must buy it), commitment tendency (I am already bidding so I must continue), and social proof (I know that buying is good because my peers are doing it).

The lollapalooza effect occurs when two or more forces are all operating in the same direction and often you don’t get just simple addition but rather you get a nuclear explosion once you reach a certain point of interaction between those forces such as a breakpoint or critical-mass is reached.

In the field of psychology the phenomenon wherein different biases layer and interlock with one another is the lollapalooza effect. It occurs when multiple different tendencies and mental models combine to act in the same direction. This makes them especially powerful drivers of behavior, and can lead to both positive and negative results.

The lollapalooza effect can cause huge negative effects but it can also cause massively positive trade-offs. So, understanding the interconnectedness of the models is critical.

Munger stated that while psychologists have been good at identifying individual biases, they are less good at figuring out how they interact and manifest in the real world, because it is difficult to run controlled experiments in that environment.

> The psychology people couldn't do experiments that were four or five things happening at once because it got too complicated for them and they couldn't publish. So they were ignoring the most important thing in their own profession. And of course the other thing that was important was to synthesize psychology with all else. And the trouble with the psychology profession is that they don't know anything about all else. — Charlie Munger

 <br>
</details>
<br>

<details>
    <summary><strong>Social proof</strong></summary>
    <br>

The kind of conformity to socially accept behavior is known as social proof. 

Social proof is considered prominent in ambiguous social situations where people are unable to determine the appropriate mode of behavior, and is driven by the assumption that the surrounding people possess more knowledge about the current situation. The effects of social influence can be seen in the tendency of large groups to conform. This is referred to in some publications as the herd behavior. 

Essentially, we are looking to those around us for clues about the ‘right’ way to behave, especially in ambiguous circumstances. At times, social proof is a stronger influence than rules – if other people are not following the guidelines, we don’t feel like we have to either. For example, if you saw that everyone was crossing a crosswalk when the light was red, you might follow their footsteps and do the same.

One of the first series of experiments to study social proof was conducted all the way back in the 1950s by Solomon Asch, a pioneer of social psychology, especially with regards to conformity. His first conformity experiment, which went on to be widely replicated within social psychology, was conducted in 1951. In this experiment, 50 college-age participants were told that they were going to participate in a vision test. Unbeknown to the participants, they entered a room with who they assumed to be other participants, but who were actually seven confederates. Each person in the room was then shown a picture of a target line next to three lines A, B, and C, and asked which line was most similar in length to the target line. The answer was always fairly obvious, however, the seven confederates would purposefully give the wrong answer. The real participant was the last to give his/her answer, after they had heard all the other answers. Asch found that over 12 different trials, participants conformed at least once 75% of the time, showing that people will often look to others for evidence and proof of what the correct answer is 4. To further investigate this notion, Asch continued to conduct experiments throughout the 1950s, which are known usually holistically referred to as the Asch conformity experiments.

It wasn’t until 1984 that the term social proof became popular, when Dr. Robert Cialdini, professor of psychology, coined it in his book Influence: The Psychology of Persuasion. In this book, Cialdini suggested that social proof was one of six key principles of persuasion.

> Lack of skepticism is often the result of our social beliefs. No one would believe such absurd nonsense as a moon made of cheese or a flying teapot when it is proposed in such an unfamiliar way. However, when we encounter equally absurd belief systems in socially or historically-familiar contexts, they seem to have a measure of proof and be established or valid. In other words, a lot of people believing some total bullshit creates a form of social proof. – Sia Mohajer

 <br>
</details>
<br>

<details>
    <summary><strong>Liking disliking bias</strong></summary>
    <br>

We tend to dislike people who dislike us and tend to judge in favor of people that we know rather than strangers.

We ignore the faults and flaws of people or products if we like or love them. Even if the mistake is unforgivable, we’re easier to accept it if it’s done by our favorite brand or an attractive person. 

We are more likely to ignore faults and comply with wishes of our friends or lovers rather than random strangers. We favor people, products, and actions associated with our favorite celebrities. Sometimes we even distort facts to facilitate love. The influence that our friends, parents, lovers, and idols exert on us can be enormous. The decisions being made from liking tendency are rarely impartial. Most of us already know that we prefer to take advice from people that we like. We also tend to more easily agree with opinions formed by people we like.

We ignore the virtues and positive aspects of people we dislike or hate. We dislike people products and actions merely associated with the object of his dislike. Disliking distortions often makes mediation between opponents locked in hatred either difficult or impossible.

This is also known as Halo effect. We all like engaging in activities with beautiful people. The Halo effect occurs when a specific, positive characteristic determines the way a person is viewed by others on other, unrelated traits. In the case of beauty, it’s been shown that we automatically assign favorable yet unrelated traits such as talent, kindness, honesty, and intelligence, with those we find physically attractive. The power of the Halo effect is that it’s mostly happening beneath the level of consciousness. Appearance is not the only quality that may skew our perceptions in favor of someone.

The next one on the list is similarity. We like people who resemble us. Whether it’s appearance, opinions, lifestyle or background, we tend to favor people who are similar to ourselves. A great example of similarity bias is the case of dress. Numerous studies suggest that we are more likely to do favors, such as giving a dime or signing a petition, to someone who looks like us.

> Hating and disliking also cause miscalculation triggered by mere association. In business, I commonly see people under-appraise both the competency and morals of competitors the dislike. This is a dangerous practice, usually disguised because it occurs on a subconscious basis. — Charlie Munger

> Love your enemies, for they tell your faults. Focus on the point discussed and not the person who is making it. — Benjamin Franklin

> Because of liking tendency we tend to like who are physically attractive, popular, cooperative, or people we have positive associations with. Also, those who are similar to us in background, opinion, lifestyle, interest, attitude, looks, values, and belief. We also like and trust anything familiar. Most people prefer to say yes to the requests of someone they know and like. It’s a natural tendency to ignore the faults of those we find likeable while doing just the opposite to the people we don’t like. — Robert Cialdini

 <br>
</details>
<br>

<details>
    <summary><strong>Confirmation bias</strong></summary>
    <br>

The tendency of the human brain to filter out information that contradicts its existing beliefs.

A confirmation bias makes people look for information that is consistent with what they already think, want, or feel, leading them to avoid, dismiss, or forget information that will require them to change their minds and behavior. When we have pre-existing beliefs, we often take facts and make them fit with these beliefs. Facts are interpreted selectively. We like to agree with the facts which support our beliefs and throw out or misinterpret the ones we don't agree with.  In short, we see the world as we want to see it, not as it is.

Confirmation bias clouds our judgment. It gives us a skewed view of information, even when it consists only of numerical figures. We know how confirmation bias gets in the way of thinking clearly. So why do we carry this bias? Accepting information that confirms our beliefs is easy and requires little mental energy. Seeking out an objective statistical rigor is challenging because our laziness prevents us from updating our thinking.

But failing to interpret information in an unbiased way can lead to serious misjudgments. It can create bad habit patterns. Research has shown that when you recall episodic memory, you will fill in information using confirmation bias, thus enforcing your memory to recall only what you believe in and refute the ones that you don't believe in. Wikipedia has a great take on confirmation bias:

> It is an important type of cognitive bias that has a significant effect on the proper functioning of society by distorting evidence-based decision-making. People display this bias when they gather or remember information selectively, or when they interpret it in a biased way. The effect is strongest for desired outcomes, for emotionally charged issues, and for deeply entrenched beliefs. People also tend to interpret ambiguous evidence as supporting their existing position. — Wikipedia

**Darwin on prejudice**: In any good scientific experiments, researchers should seek to falsify their hypotheses, not to confirm them. Darwin knew this really well and was determined to avoid prejudice. Darwin goes through remarkable lengths to prevent what psychologists call “confirmation bias” and other forms of psychological misjudgment that would deteriorate his work. He undoubtedly realized that he can fool himself subconsciously, and put in place various habits to keep prejudice in check.

> I have steadily endeavoured to keep my mind free so as to give up any hypothesis, however much beloved (and I cannot resist forming one on every subject), as soon as facts are shown to be opposed to it. Indeed, I have had no choice but to act in this manner, for with the exception of the Coral Reefs, I cannot remember a single ﬁrst-formed hypothesis which had not after a time to be given up or greatly modiﬁed. — Charles Darwin

Even when Darwin began to appreciate the formation of new species, a theory that had been a mystery to him for years, he was anxious to work on it so as to avoid any prejudice.

> The result of this would be the formation of new species. Here then I had at last got a theory by which to work; but I was so anxious to avoid prejudice, that I determined not for some time to write even the briefest sketch of it. — Charles Darwin

Our natural inclination is to cling to our beliefs, particularly if we are reinforced by recent experiences–a flaw within our makeup. Darwin was good at realizing this flaw. If all scientists do a better job of addressing their confirmation bias, we could save a huge amount of time and money. Not everyone is Darwin, so we must remember not to take science at face value because the reporting could be biased due to confirmation bias.

**Kill the belief bubble**: Practice stress testing your beliefs. Try having a non-emotional discussion or debate with that person and see how they came up with their belief. This could be any topic such as religious, political, or parenting. Then see how your beliefs are different than the person you are discussing this topic with.

- Pick something from your list to stress test on. Be honest with yourself while conducting this exercise. Remember why you are doing it in the first place.
- Conduct research and list all the opposing viewpoints for your beliefs. Try to see things from this perspective while staying objective. Compare them how they differ from your existing beliefs.
- Once you think you have a grasp of all sides of the issue. What did you learn that will kill or keep your existing beliefs? Can your new beliefs be validated? If so, how can it be objectively validated?

Even if you were right all along, it is worth conducting this exercise to stress test your ideas. The more rigor you apply, the better informed you will be. This is where growth lies.

**Confirmation bias & self-confidence**: Many people deny that they are affected by confirmation bias. After all, most of us see ourselves as intelligent and rational people. But we don't give enough credit to our emotional state. Not understanding this can create cognitive dissonance which we mistake it for self-confidence. We are bombarded by information. It comes from other people, the media, our experience, and various other sources. Our minds must find means of encoding, storing, and retrieving the data we are exposed to. One way we do this is by developing cognitive shortcuts and models. These can be either useful or unhelpful. Constantly evaluating our worldview is exhausting, so we prefer to strengthen it instead. Plus holding different ideas in our head is hard work. It’s much easier to just focus on one and create wrong models in our head leading to over-confidence. A very difficult journey to embark on, but we must at least strive to fight for our confirmation biases.

> Man is not a rational animal, he is a rationalizing animal. — Robert Heinlein

> As a man wants, so shall he believe. — Greek Philosopher

> The eye sees only what the mind is prepared to comprehend. — Robertson Davies

> One of the biggest problems with the world today is that we have large groups of people who will accept whatever they hear on the grapevine, just because it suits their worldview—not because it is actually true or because they have evidence to support it. — Neil deGrasse Tyson

> The most difficult subjects can be explained to the most slow-witted man if he has not formed any idea of them already; but the simplest thing cannot be made clear to the most intelligent man if he is firmly persuaded that he knows already, without a shadow of doubt, what is laid before him. — Leo Tolstoy

> Beliefs can survive potent logical or empirical challenges. They can survive and even be bolstered by evidence that most uncommitted observers would agree logically demands some weakening of such beliefs. They can even survive the destruction of their original evidential bases. — Lee Ross and Craig Anderson

> The confirmation bias is so fundamental to your development and your reality that you might not even realize it is happening. We look for evidence that supports our beliefs and opinions about the world but excludes those that run contrary to our own… In an attempt to simplify the world and make it conform to our expectations, we have been blessed with the gift of cognitive biases. — Sia Mohajer

> The human understanding when it has once adopted an opinion, draws all things else to support and agree with it. And though there be a greater number and weight of instances to be found on the other side, yet these it either neglects and despises, or else by some distinction sets aside and rejects. — Francis Bacon

> The desire to be right and the desire to have been right are two desires, and the sooner we separate them the better off we are. The desire to be right is the thirst for truth. On all counts, both practical and theoretical, there is nothing but good to be said for it. The desire to have been right, on the other hand, is the pride that goeth before a fall. It stands in the way of our seeing we were wrong, and thus blocks the progress of our knowledge. — Willard V. Quine and J.S. Ullian

> When you forget that people and ideas are separate, your entire thinking process is laden with a crippling burden: to protect your beliefs like you protect your body. — Tim Urban

> The number one thing that clouds us from being able to see reality is that we have preconceived notions of the way it should be. — Naval Ravikant

> What the human being is best at doing is interpreting all new information so that their prior conclusions remain intact. — Warren Buffett

 <br>
</details>
<br>

<details>
    <summary><strong>Reciprocation</strong></summary>
    <br>

Act of doing something nice for someone with the expectation that the favor will be returned.

Have you ever been handed a free sample at a local grocery store? These small acts are meant to initiate reciprocation tendency, a tendency to reciprocate the favors and concession. Even if this gift is unwanted, receiving it can still trigger a need to repay the gift, usually in the form of purchasing whatever is being sold. It’s a powerful technique the sales and marketing world utilizes. In social psychology, reciprocity is a social norm of responding to a positive action with another positive action, rewarding kind actions. As a social construct, reciprocity means that in response to friendly actions, people are frequently much nicer and much more cooperative than predicted by the self-interest model.

On one hand, reciprocity makes it possible to build continuing relationships and exchanges. But on the other reciprocity makes you feel obligated to repay positive actions, such as favors, even if they are unwanted. Reciprocation is the act of doing something nice for someone, with the expectation that they will do something nice in return for you. Reciprocity is great a societal level but more complicated at the individual level. Women, in particular, often report on the pressure they feel after receiving expensive gifts or dinners.

One often realizes the power of this tendency when one has to do a reciprocating act even if one does not want to do it. It’s almost like an obligation. For example, you have a higher probability to invite a person to your party even if you dislike the person, but just because he invited you to his party earlier. Sales people at various organizations are taught to use this tendency, knowingly or unknowingly.
Author Robert Cialdini (Ph.D.) explores the mental bias of reciprocation tendency in his book, Influence: The Psychology of Persuasion. He defines reciprocation tendency as the automatic tendency for humans to try to reciprocate in kind what others have done for us. And it’s a powerful force. Cialdini argues that this bias can produce a “yes” response from someone who, under normal circumstances, would certainly refuse.

This trait has created in humans an intense psychological reaction to being in a state of obligation: we hate it. If someone does us a favor, we feel like we owe them, and will often go to great lengths to repay the debt that’s owed as quickly as possible. If someone does us disfavor, we often feel like we need to “get back at them” for the injustice we feel we have suffered. The key to genuine relationships lies having no expectations. In communal relationships like marriage, friendship, and the parent-child relationship, the pressure of reciprocal theory barely ever plays out. It’s the unconditional willingness to help the other side. But some symmetry seems to be the best to avoid being taken advantage of.

**Positive and negative reciprocity**: Positive reciprocity occurs when an action committed by one individual that has a positive effect on someone else is returned with an action that has an approximately equal positive effect. For example, if someone takes care of another person's dog, the person who received this favor should then return this action with another favor such as with a small gift. However, the reciprocated action should be approximately equal to the first action in terms of positive value, otherwise this can result in an uncomfortable social situation.

Negative reciprocity occurs when an action that has a negative effect on someone is returned with an action that has an approximately equal negative effect. For example, if an individual commits a violent act against a person, it is expected that person would return with a similar act of violence. If, however, the reaction to the initial negative action is not approximately equal in negative value, this violates the norm of reciprocity and what is prescribed as allowable.

**Reciprocal concessions**: One form of this more subtle form of reciprocity is the idea of reciprocal concessions in which the requester lowers his/her initial request, making the respondent more likely to agree to a second request. Under the rule of reciprocity, we are obligated to concede to someone who has made a concession to us. The rule of reciprocity operates in reciprocal concessions in two ways. First, an individual is pressured to reciprocate one concession for another by nature of the rule itself. Second, because the individual who initially concedes can expect to have the other person concede in return, this person is free to make the concession in the first place. If there were no social pressure to return the concession, an individual runs the risk of giving up something and getting nothing in return. Mutual concession is a procedure that can promote compromise in a group so that individuals can refocus their efforts toward achieving a common goal.

 <br>
</details>
<br>

<details>
    <summary><strong>Reason respecting tendency</strong></summary>
    <br>

Ask questions to gain better understanding of the world. 

Failure to reason discourages first principles thinking. Failure to reason is common within workplace environment. As adults, we learn that we should work hard because we are an integral of the company. Employees tend to buy into this idea without asking why or how they are an integral of the company. Are employees still integral of the organization during an economic downturn? We are more likely to comply with something or to learn something when we are given the *why* behind it. The *why* strengthens our learning but can be dangerous as we will often learn and comply even when the reason behind it is false.

One way to jump from linear to non-linear results is to think in first-principles. First-principles thinking can be adopted by asking a lot of questions. It is often called r*easoning from the first principles* by asking *why*? The idea is to break down complicated problems into basic elements and then reassemble them from the ground up. This is the best way to reverse-engineer hard problems that are challenging to understand. Aristotles used first-principles thinking to understand things around him. Over two thousand years ago, Aristotle defined a first principle as *the first basis from which a thing is known*.

In every systematic inquiry (methodos) where there are first principles, or causes, or elements, knowledge and science result from acquiring knowledge of these; for we think we know something just in case we acquire knowledge of the primary causes, the primary first principles, all the way to the elements. In 1970s, Harvard psychologist, Ellen Langer conducted a study of the power of the word “because.” Langer had participants request to break in on a line of people waiting to use a busy copy machine on a college campus. The researchers had the people use three different, specifically worded requests to break in line:

- “Excuse me, I have 5 pages. May I use the xerox machine?”
- 60% of people let the participant to break in line.
- “Excuse me, I have 5 pages. May I use the xerox machine, because I have to make copies?”
- 93% of people let the participant to break in line.
- “Excuse me, I have 5 pages. May I use the xerox machine, because I’m in a rush?”
- 94% of people let the participant to break in line.

Langer showed that when asking for a favor from a stranger, simply giving a reason for the request (because), even if it’s artificial (because I have to make copies), greatly increases the odds of the person complying. Reasoning from first principles, rather than by analogy (previous experiences) can open up the door to learning, better work results, or prevent manipulation. First principles thinking can be easy to describe, but can be quite difficult to practice.

**Why is reasoning necessary?** We love to have reasons as Langer's experiment proves people to comply. Therefore, make sure to share the reasons why the task is important before delegating. Charlie Munger shares the story of Carl Braun, the creator of CF Braun Engineering Company —

> His rule for all the Braun Company’s communications was called the five W’s – you had to tell who was going to do what, where, when and why. And if you wrote a letter or directive in the Braun Company telling somebody to do something, and you didn’t tell him why, you could get fired. In fact, you would get fired if you did it twice. You might ask why that is so important? Well, again that’s a rule of psychology. Just as you think better if you array knowledge on a bunch of models that are basically answers to the question, why, why, why, if you always tell people why, they’ll understand it better, they’ll consider it more important, and they’ll be more likely to comply. Even if they don’t understand your reason, they’ll be more likely to comply. So there’s an iron rule that just as you want to start getting worldly wisdom by asking why, why, why in communicating with other people about everything, you want to include why, why, why.

Carl Braun knew the ideas got through when reasons for the ideas were meticulously laid out. *Who* was to do *What*, *Where*, *When* and *Why*. However, reason-respecting tendency is so strong that a requester can give meaningless or incorrect reasons which will make a person on receiving end to comply with orders and requests. Langer's experiment again proves this point. Is ‘I have to make some copies’ really an important explanation for people to comply to let the person break in line? Our need for making sense makes us believe in nonsense artificial reasons. It turns people are addicted to the word “because” and are just looking for answers not the reasons or a better understanding of it. Charlie Munger shared *Reason Respecting Tendency* bias in his famous lecture *Psychology of Human Misjudgement.*

> There is in man, particularly one in an advanced culture, a natural love of accurate cognition and a joy in its exercise. This accounts for the widespread popularity of crossword puzzles, other puzzles, and bridge and chess columns, as well as all games requiring mental skill.This tendency has an obvious implication. It makes man especially prone to learn well when a would-be teacher gives correct reasons for what is taught, instead of simply laying out the desired belief ex cathedra with no reasons given. Few practices, therefore, are wiser than not only thinking through reasons before giving orders but also communicating these reasons to the recipient of the order. In general, learning is most easily assimilated and used when, lifelong, people consistently hang their experience, actual and vicarious, on a latticework of theory answering the question: Why? Unfortunately, Reason Respecting Tendency is so strong that even a person’s giving of meaningless or incorrect reasons will increase compliance with his orders and requests…This sort of unfortunate byproduct of Reason-Respecting Tendency is a conditioned reflex, based on a widespread appreciation of the importance of reasons. And, naturally, the practice of laying out various claptrap reasons is much used by commercial and cult “compliance practitioners” to help them get what they don’t deserve.

So what do you do to not get mis-influenced by intentional reasonings?

**First principles thinking**: To reverse engineer any complex problem use the first-principles thinking by breaking down the problem into basic elements and then reassemble from the ground up. Asking why can remove all assumptions and misconceptions. It leaves you with basic elements. Elon Musk is well known for using first principles mindset and shares his thoughts:

> You look at the fundamentals and construct your reasoning from that and then see if you have a conclusion that works or doesn’t work. And it may or may not be different from what people have done in the past. It’s harder to think that way, though.

> I think people’s thinking process is too bound by convention or analogy to prior experiences. It’s rare that people try to think of something on a first principles basis. They’ll say, “We’ll do that because it’s always been done that way.” Or they’ll not do it because “Well, nobody’s ever done that, so it must not be good. But that’s just a ridiculous way to think. You have to build up the reasoning from the ground up—“from the first principles” is the phrase that’s used in physics. You look at the fundamentals and construct your reasoning from that, and then you see if you have a conclusion that works or doesn’t work, and it may or may not be different from what people have done in the past.

Richard Feynman was also known for using first principles to understand the basics —

> I don’t know what’s the matter with people: they don’t learn by understanding; they learn by some other way—by rote or something. Their knowledge is so fragile!

How to implement first-principles?

**The five Ws**: The five Ws are questions whose answers are considered basic in information gathering or problem solving. They are often mentioned in journalism, research and police investigations. Some authors also add a sixth question, how, to the list.
- Who
- What
- Where
- When
- Why

The last W is important because you can uncover a lot of details by asking *Why* many times. The Toyota's *Five Whys* is a great example of a technique to help you apply second order thinking. Why did that problem happen? Then ask why five times. Why would we make that decision? Then ask why five times.

**Socratic questioning**: Socratic questioning was named after Socrates and is a form of disciplined questioning to explore complex ideas, get to the truth of things, to explore problems, uncover assumptions and analyze concepts and to distinguish what we know from what we do not know. According to Plato, one of his students, Socrates believed that “the disciplined practice of thoughtful questioning enables the scholar/student to examine ideas and be able to determine the validity of those ideas.” This process stops from relying on gut and limits strong emotional responses.
1. Getting students to clarify their thinking and explore the origin of their thinking. Examples: why do you say that? Could you explain further?
2. Challenging students about assumptions. Examples: is this always the case? Why do you think that this assumption holds here?
3. Providing evidence as a basis for arguments. Examples: Why do you say that? Is there reason to doubt this evidence?
4. Discovering alternative viewpoints and perspectives and conflicts between contentions. Examples: what is the counter-argument? Can/did anyone see this another way?
5. Exploring implications and consequences. Examples: But if...happened, what else would result? How does...affect...?
6. Questioning the question. Examples: why do you think that I asked that question? Why was that question important? Which of your questions turned out to be the most useful?

**The Feynman technique**: Nobel prize-winning physicist Richard Feynman used to ensure he understood anything he studied better than anyone else. There are four steps to the Feynman Learning Technique:
1. Choose a concept you want to learn about.
2. Pretend you are teaching it to someone else in plain language.
3. Identify gaps in your explanation and go back to the source material to better understand it.
4. Review and simplify further in simpler terms.

Kids consistently push their parents with questions but the adults think it is stunning how quickly they learn. However, it is natural for kids to be curious and creative during their formative years because they are trying to understand the world around them. Adults choose not to be creative because they fail to reason. Busy is the enemy of adults and as we grow older, we rely on general convention but this puts blinders on perspectives and thoughts because we outsource our thinking to someone else. To defy conventional wisdom, we must think for ourselves and reason from first principles. Analogies are great to understand a topic further, but they cannot replace the understanding of basic knowledge. Thinking in first principles won't imprison us with someone else's thoughts. Doing this will unleash creative and original thinking.

> I think most people can learn a lot more than they think they can. They sell themselves short without trying. One bit of advice: it is important to view knowledge as sort of a semantic tree — make sure you understand the fundamental principles, i.e., the trunk and big branches, before you get into the leaves/details or there is nothing for them to hang on to. — Elon Musk

> As to methods, there may be a million and then some, but principles are few. The man who grasps principles can successfully select his own methods. The man who tries methods, ignoring principles, is sure to have trouble. — Harrington Emerson

> The idea is that reasoning from first principles is reasoning like a scientist. You take core facts and observations and use them to puzzle together a conclusion, kind of like a chef playing around with raw ingredients to try to make them into something good. By doing this puzzling, a chef eventually writes a new recipe. The other kind of reasoning—reasoning by analogy—happens when you look at the way things are already done and you essentially copy it, with maybe a little personal tweak here and there—kind of like a cook following an already written recipe. A pure verbatim recipe-copying cook and a pure independently inventive chef are the two extreme ends of what is, of course, a spectrum. But for any particular of your life that involves reasoning and decision making, wherever you happen to be on the spectrum, your reasoning process can usually be boiled down to fundamentally chef-like or fundamentally cook-like. Creating vs. copying. Originality vs. conformity. — Wait but why

> To understand is to know what to do. — Wittgenstein

 <br>
</details>
<br>

<details>
    <summary><strong>Kantian fairness tendency</strong></summary>
    <br>

The pursuit of fairness for everyone and everything. We believe in people being treated equally, but that is not the case. The definition of fairness, of how people should be treated differs from person to person, and we should adjust our behavior accordingly.

The word, Kant, refers to the philosophical framework created by eighteenth century German philosopher Immanuel Kant. According to Wikipedia, Kant’s ethics are founded on his view of rationality as the ultimate good and his belief that all people are fundamentally rational beings.

If humans are irrational then what-is-fair must be flawed. The fairness of anything is dependent on personal situation and every personal situation is different.

Charlie Munger has spoken about our obsession of fairness in his UCSB talk.

> It is not always recognized that, to function best, morality should sometimes appear unfair, like most worldly outcomes. The craving for perfect fairness causes a lot of terrible problems in system function. Some systems should be made deliberately unfair to individuals because they’ll be fairer on average for all of us. I frequently cite the example of having your career over, in the Navy, if your ship goes aground, even if it wasn’t your fault. I say the lack of justice for the one guy that wasn’t at fault is way more than made up by a greater justice for everybody when every captain of a ship always sweats blood to make sure the ship doesn’t go aground. Tolerating a little unfairness to some to get a greater fairness for all is a model I recommend to all of you. But again, I wouldn’t put it in your assigned college work if you want to be graded well, particularly in a modern law school wherein there is usually an over-love of fairness-seeking process.

Munger goes on about the same topic in The Psychology of Human Misjudgement:

> Kant was famous for his “categorical imperative,” a sort of a “golden rule” that required humans to follow those behavior patterns that, if followed by all others, would make the surrounding human system work best for everybody. And it is not too much to say that modern acculturated man displays, and expects from others, a lot of fairness as thus defined by Kant.

> In a small community having a one-way bridge or tunnel for autos, it is the norm in the United States to see a lot of reciprocal courtesy, despite the absence of signs or signals. And many freeway drivers, including myself, will often let other drivers come in front of them, in lane changes or the like, because that is the courtesy they desire when roles are reversed. Moreover, there is, in modern human culture, a lot of courteous lining up by strangers so that all are served on a “firstcome-first-served” basis.

> Also, strangers often voluntarily share equally in unexpected, unearned good and bad fortune. And, as an obverse consequence of such “fair-sharing” conduct, much reactive hostility occurs when fairsharing is expected yet not provided. It is interesting how the world’s slavery was pretty well abolished during the last three centuries after being tolerated for a great many previous centuries during which it coexisted with the world’s major religions. My guess is that Kantian Fairness Tendency was a major contributor to this result.

When we are not treated fairly, we often become angry or frustrated. The pursuit of absolute fairness can cause severe problems, and some systems should appear unfair as they will be more beneficial on average for all. Life isn’t fair, but many cannot accept this.

 <br>
</details>

## Biology
| Model | Definition | 
| -------------|:-------------:|
| _Red queen effect_ | Survival in a competitive environment usually requires adaptation and velocity, so doing nothing often means being left behind. |

<details>
    <summary><strong>Red queen effect</strong></summary>
    <br>

Survival in a competitive environment usually requires adaptation and velocity, so doing nothing often means being left behind.

The Red Queen Effect means that staying in the same place is falling behind. Surviving another day means we have to co-evolve with the systems we interact with. If all animals evolved at the same rate, there would be no change in the relative interactions between species. However, not all animals evolve at the same rate. As Darwin observed, some are more “responsive to change” than others.

> It is not the strongest of the species that survives, nor the most intelligent, but the one most responsive to change. — Charles Darwin

Where does the phrase Red Queen come from? The Red Queen is from Lewis Carroll’s novel “Through the Looking Glass.” The Red Queen notes to Alice that in the Red Queen’s world, Alice will have to run as fast as she can to stay in place and twice as quickly to move forward.

> Now, here, you see, it takes all the running you can do, to keep in the same place. If you want to get somewhere else, you must run at least twice as fast as that! — Lewis Carroll

The evolve-or-die is the fact of nature. The effect is an evolutionary hypothesis that organisms must constantly evolve to survive, reproduce, and hopefully gain an advantage. One must work smarter and not faster to succeed.

Of course, in the modern-day, we have to plan our moves strategically to be successful in this digitized world.

> The great lesson in microeconomics is to discriminate between when technology is going to help you and when it’s going to kill you. — Charlie Munger

> The promised benefits from these textile investments were illusory. Many of our competitors, both domestic and foreign, were stepping up to the same kind of expenditures and, once enough companies did so, their reduced costs became the baseline for reduced prices industry wide. Viewed individually, each company’s capital investment decision appeared cost-effective and rational; viewed collectively, the decisions neutralized each other and were irrational. — Warren Buffett

People who sacrifice their present for the future are the ones who see the best results, and the Red Queen Effect is a great principle backing this idea. Although current generations may die to the process of natural selection, future generations stand to benefit greatly from their sacrifice. This evolutionary process persists in all areas of the world, from business transactions to biological reactions.

Siddhartha Mukherjee, Pulitzer-prize-winner for the book The Emperor of All Maladies, describes the red queen in the context of drugs and cancer.

> In August 2000, Jerry Mayfield, a forty-one-year-old Louisiana policeman diagnosed with CML, began treatment with Gleevec. Mayfield’s cancer responded briskly at first. The fraction of leukemic cells in his bone marrow dropped over six months. His blood count normalized and his symptoms improved; he felt rejuvenated—“like a new man [on] a wonderful drug.” But the response was short-lived. In the winter of 2003, Mayfield’s CML stopped responding. Moshe Talpaz, the oncologist treating Mayfield in Houston, increased the dose of Gleevec, then increased it again, hoping to outpace the leukemia. But by October of that year, there was no response. Leukemia cells had fully recolonized his bone marrow and blood and invaded his spleen. Mayfield’s cancer had become resistant to targeted therapy…

> … Even targeted therapy, then, was a cat-and-mouse game. One could direct endless arrows at the Achilles’ heel of cancer, but the disease might simply shift its foot, switching one vulnerability for another. We were locked in a perpetual battle with a volatile combatant. When CML cells kicked Gleevec away, only a different molecular variant would drive them down, and when they outgrew that drug, then we would need the next-generation drug. If the vigilance was dropped, even for a moment, then the weight of the battle would shift. In Lewis Carroll’s Through the Looking-Glass, the Red Queen tells Alice that the world keeps shifting so quickly under her feet that she has to keep running just to keep her position. This is our predicament with cancer: we are forced to keep running merely to keep still.

 <br>
</details>

## Further reading
<details>
    <summary><strong>References</strong></summary>
    <br>

- Poor Charlie's Almanack: The Wit and Wisdom of Charles T. Munger, Expanded Third Edition
- [All models are wrong](https://en.wikipedia.org/wiki/All_models_are_wrong)
</details>
<br />
